 基础 ✅

### 简介

​	Redis(Remote Dictionary Server，远程数据服务)是一个开源缓存数据库，其中包含五大数据结构，是基于键值的存储服务系统，并且高性能、功能丰富。

### 结构化存储

事务处理系统或者RDBMS 关系数据库，传统的结构化存储强调的是，

结构化的数据，例如关系表，

然后强一致性，数据一致性，级联删除，外键等等，维护数据的一致性

随机访问，SQL， CURD，以及索引

### 非结构化存储

GFS 的主要思想包括：

（1）用 master 来管理 metadata。
（2）文件使用 64MB 的 chunks 来存储，并且在不同的 server 上保存多个副本。
（3）自动容错，自动错误恢复。

非结构化存储 就是分布式的文件系统 具有高可用的性能，以及高扩展性和吞吐率，当然必须有一些容错机制

Google 设计 gfs 最初的目的是为了存储海量的日志文件以及网页等文本信息，并且对其进行批量处理（例如配合 mapreduce 为文档建立倒排索引，计算网页 PageRank 等）。和结构化存储系统相比，虽然分布式文件系统的可扩展性，吞吐率都非常好，但是几乎无法支持随机访问（random access）操作，通常只能进行文件进行追加（append）操作。而这样的限制使得非结构化存储系统很难面对那些低延时，实时性较强的应用。

### 半结构化存储

半结构化存储就是最近比较火的NoSQL，因为既保留了RDBMS的随机访问的性质，又有高扩展性和容错机制和错误处理

### 与Redis特点对比

##### MySQL的特点及优缺点

1. 关系型数据库的特点

   - 数据关系模型基于关系模型，结构化存储，完整性约束；

   - 基于二维表及其之间的联系，需要连接、并、交、差、除等数据操作；

   - 采用结构化的查询语言（SQL）做数据读写；

   - 操作需要数据的一致性，需要事务甚至是强一致性。
2. 关系型数据库的优点

   - 保持数据的一致性（事务处理）；

   - 可以进行join等复杂查询；

   - 通用化，技术成熟。
3. 关系型数据库的缺点
- 数据读写必须经过sql解析，大量数据、高并发下读写性能不足；
   - 对数据做读写，或修改数据结构时需要加锁，影响并发操作；
- 无法适应非结构化存储；
   - 扩展困难；
- 昂贵、复杂。

**理解：**

关系型数据库由连接层，服务层，数据引擎层和物理层四层组成

Mysql的优点： 保持数据一致性，可以用join跨表进行复杂查询，通用化，技术成熟

Redis的优点：基本支持分布式，容易扩展，高并发，大数据下读写能力强，简单，弱结构化存储



##### Reids的特点及优缺点

1. noSQL 的特点

   - 非结构化的存储。

   - 基于多维关系模型。

   - 具有特有的使用场景。

2. noSQL 的优点

   - 高并发，大数据下读写能力较强。

   - 基本支持分布式，易于扩展，可伸缩。

   - 简单，弱结构化存储。

3. noSQL 的缺点

   - join等复杂操作能力较弱。

   - 事务支持较弱。

   - 通用性差。

   - 无完整约束复杂业务场景支持较差。

### 数据结构

​	redis中主要有五种数据结构，具体如下：

![](../assets/redis数据结构.png)



### Redis特性

1. 速度快

   根据官方数据，redis 在处理100,000ops级别的操作时，完全没有问题。其速度快的主要原因如下：

- 数据存储在主存中；

  原来是缓存..放在主存中 也怪不得快，因此需要高的命中率

- redis是使用c语言写的，并且原作者实现的代码水平受到广泛认可；

- 采用单线程处理网络请求（redis本身不是单线程），单线程也可以处理高并发请求，想多核可启动多实例。这样就避免了频繁地对锁资源进行争夺，提高了效率；

  redis 本身不是单线程，但是在处理网络请求的时候，是单线程

2. 持久化（断电不丢失数据）

   Redis将所有的数据保存在内存中，对数据的更新将异步保存到磁盘上。

3. 多种数据结构

   redis 中目前主要有五种数据结构：字符串、列表、集合、有序结合、哈希散列。除了以上五种数据结构，redis还引入了位图(BitMap)、超小内存唯一值计数(HyperLogLog)、地理信息定位(GEO)

   主要前面这三点吧

4. 支持多种语言客户端

5. 功能丰富

   如发布订阅（实现很多基于消息的功能）、事务、lua脚本（编写自定义命令）、pipeline（提高客户端并发效率）

6. 简单

- redis3.0版本之后提供了分布式集群功能，但其核心单机代码只有23,000 c 语言写的代码。
- 不依赖于外部库
- 单线程模型

7. 复制

   将主服务器上的数据同步到从服务器上，这样为高可用和分布式打下了基础。

8. 高可用、分布式

   ![](../assets/redis 高可用分布式.png)

   注：什么是高可用？

   ​	高可用HA（High Availability）是分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计减少系统不能提供服务的时间。

   ​	假设系统一直能够提供服务，我们说系统的可用性是100%。如果系统每运行100个时间单位，会有1个时间单位无法提供服务，我们说系统的可用性是99%。很多公司的高可用目标是4个9，也就是99.99%，这就意味着，系统的年停机时间为8.76个小时。

   ​	百度的搜索首页，是业内公认高可用保障非常出色的系统，甚至人们会通过www.baidu.com 能不能访问来判断“网络的连通性”，百度高可用的服务让人留下啦“网络通畅，百度就能访问”，“百度打不开，应该是网络连不上”的印象，这其实是对百度HA最高的褒奖。

   注：什么是复制，复制和分布式的关系？

# Redis典型使用场景

- 缓存系统

  ![](../assets/主流应用架构.png)

  什么事熔断和回种？

- 计数器

  redis 提供了 Incre 这样的命令，可以在单线程下进行非常准确高效的计数。

  ![](../assets/redis 计数器.png)

- 消息队列系统

  redis中自带一个较为简单的消息队列系统。

- 排行榜

  通过有序结合实现。

- 社交网络

  粉丝数、关注数等内容十分适合使用redis实现。

- 实时系统

  利用位图实现布隆过滤器，可以对垃圾邮件进行过滤或者对重复数据去重。

  //用位图 做统计嘛？

### 安装

redis 下载官方[链接](https://redis.io/download)，

```shell
$ wget -P /opt http://download.redis.io/releases/redis-5.0.3.tar.gz
$ cd /opt
$ tar -zxvf redis-5.0.3.tar.gz
$ cd redis-5.0.3
$ make
```

- gcc缺失错误：gcc是linux下的一个编译程序，是C程序的编译工具。需要手动安装gcc。

### Redis可执行文件说明

### Redis的三种启动方式

1. 最简启动

   使用 redis-server 进行启动

2. 动态参数启动redis

   redis-server —port 6380

3. 通过配置文件启动 redis

   redis-server configPath

注：

- 生产环境建议使用配置文件启动

  ​	因为redis为单线程处理网络请求，所以在一台服务器上往往会部署多个redis程序，单机多实例配置文件可以用端口区分开。

### Redis常用配置

- Daemonize：是否是守护进程(no|yes)，建议为yes
- Port：redis对外端口号
- Logfile：redis 系统日志，此处指定日志名称
- Dir：redis工作目录，即日志和持久化文件存储位置

额外内容：

- RDB config
- AOF config
- slow log config
- maxMemory

### 主流应用架构

主流应用架构如图所示：

![](../assets/主流应用架构.png)

- 熔断：即存储层挂掉，缓存层直接将用户请求存储并返回结果（即使没有数据），做到有效止损。

### 缓存中间件

​	目前缓存中间件主要有两种开源技术，分别是Memcache和Redis

##### Memcache

​	简单易用，代码层次类似Hash，其特点如下：

- 支持简单数据类型；
- 不支持数据持久化存储，一旦服务器宕机，数据没有办法保存下来；
- 不支持主从同步
- 不支持分片

##### Redis

- 数据类型丰富，支持set、list等结构；

  比memocache多了 set Linkedlist sortedset这些数据结构

- 支持磁盘持久化存储数据；

- 支持主从同步；？？

  这就涉及到我之前提出的问题，什么叫做主从同步

- 支持分片



### API 的理解与使用（通用命令）

- redis-cli 进入命令行 如同mysql那样的界面

- keys（O(n)）

  遍历出所有的key，如

  ```java
  keys *			//该命令会打印出所有的key
  keys he*		//该命令会打印出所有以he开头的key，*号匹配多个字符
  keys he[h-l]*	//第三个字母在h-l范围内
  keys he?		//？只匹配一个字符
  ```

  ​	Keys 一般不在生产环境使用，一般生产环境下数据非常多，keys是一个O(n)级别的命令，而且redis是单线程处理网络请求，使用该命令会造成程序性能下降。

  ​	keys可以放在从节点使用，由于主从复制功能，从节点数据与主节点数据一致且不投入生产环境，在该节点可以使用keys这种重命令。

  主节点，从节点，这种长命令

- dbsize（O(1)）

  计算key的总数，其时间复杂度为O(1)，可以随便使用

- exists key（O(1)）

  检查key是否存在，存在则返回1，不存在返回0，时间复杂度为O(1)，一般情况下可以随便使用，如：

  ```java
  set a b
  exists a		//1
  del a
  exists a		//0
  ```

- del key[key...]（O(1)）

  删除指定 key-value

- expire key seconds（O(1)）

  设置key在seconds秒后过期

  - ttl key，查看 key 剩余的过期时间
  - persisit key, 去掉 key 的过期时间

  ```java
  set hello world		//OK
  expire hello 20		//(integer)1
  ttl hello			//(integer)16
  get hello			//"world"
  ttl hello			//(integer)-2，-2代表已经不存在了
  get hello			//nil
  ```

  ```java
  set hello world		//OK
  expire hello 20		//(integer)1
  ttl hello			//(integer)16
  persisit hello		//(integer)1
  ttl hello			//(integer)-1，-1代表key存在，且没有过期时间
  get hello			//"world"
  ```

- type key（O(1)）

  返回key的类型

### 单线程

##### 单线程模型

​	redis 单线程处理网络请求，其模型如下：

![](../assets/redis 单线程模型.png)

##### 为什么单线程这么快

- 纯内存

- 非阻塞 io

  ![](../assets/redis非阻塞io.png)

- 避免线程切换和竞争时的资源消耗

##### 单线程的注意点

- 一次只执行一条命令

  单线程执行网络请求，所以一次只执行一条命令，同时又是非阻塞的，所以

- 拒绝长命令，如keys

# 数据结构和内部编码

### 底层数据结构详解 ✅

##### 整体底层数据结构图

![](../assets/redis%E5%86%85%E9%83%A8%E7%BB%93%E6%9E%84%E5%92%8C%E7%BC%96%E7%A0%81.png)

##### SDS

1. 简介

   Redis 是用 C 语言写的，但是对于Redis的字符串，却不是 C 语言中的字符串（即以空字符’\0’结尾的字符数组），它是自己构建了一种名为 简单动态字符串（simple dynamic string,SDS）的抽象类型，并将 SDS 作为 Redis的默认字符串表示。

   如下例所示：

   ```shell
   redis>SET msg "hello world"
   OK
   ```

   设置一个key= msg，value = hello world 的新键值对，他们底层是数据结构将会是：

   - 键（key）是一个字符串对象，对象的底层实现是一个保存着字符串“msg” 的SDS；
   - 值（value）也是一个字符串对象，对象的底层实现是一个保存着字符串“hello world” 的SDS。

   

2. sds的定义

   一个String SDS的结构示意图

   ```c
   // 保存字符串对象的结构  
   struct sdshdr {  
         
       // buf 中已占用空间的长度  
       int len;  
     
       // buf 中剩余可用空间的长度  
       int free;  
     
       // 数据空间  
       char buf[];  一个buf数组作为字符串的数字空间
   };  
   ```

   实例如下：

   ![](../assets/sds 实例.png)

   我们看上面对于 SDS 数据类型的定义：

   - len 保存了SDS保存字符串的长度

   - buf[] 数组用来保存字符串的每个元素

   - free j记录了 buf 数组中未使用的字节数量

3. 与c语言中字符串的区别

   有一个free 一个length 两个属性，可以判断当前字符串的长度，可以常数级获取字符串长度，并且可以杜绝缓冲区溢出，并进行扩容

   - **常数复杂度获取字符串长度**

     由于 len 属性的存在，我们获取 SDS 字符串的长度只需要读取 len 属性，时间复杂度为 O(1)。而对于 C 语言，获取字符串的长度通常是经过遍历计数来实现的，时间复杂度为 O(n)。通过 strlen key 命令可以获取 key 的字符串长度。

   - **杜绝缓冲区溢出**

     C 字符串 不记录字符串长度，除了获取的时候复杂度高以外，还容易导致缓冲区溢出。

     假设程序中有两个在内存中紧邻着的 字符串 s1 和 s2，其中s1 保存了字符串“redis”，二s2 则保存了字符串“MongoDb”：

     ![](../assets/sds杜绝缓冲区溢出1.png)

     如果我们现在将s1 的内容修改为**redis cluster**，但是又忘了重新为s1 分配足够的空间，这时候就会出现以下问题：

     ![](../assets/sds 杜绝缓冲区溢出2.png)

     我们可以看到，原本s2 中的内容已经被S1的内容给占领了，s2 现在为 cluster，而不是“Mongodb”。

     Redis 中SDS 的空间分配策略完全杜绝了发生缓冲区溢出的可能性：

     当我们需要对一个SDS 进行修改的时候，redis 会在执行拼接操作之前，预先检查给定SDS 空间是否足够，如果不够，会先拓展SDS 的空间，然后再执行拼接操作：

     ![](../assets/sds杜绝缓冲区溢出3.png)

   - **减少修改字符串的内存重新分配次数**

     C语言字符串在进行字符串的扩充和收缩的时候，都会面临着内存空间的重新分配问题。

     - 字符串拼接会产生字符串的内存空间的扩充，在拼接的过程中，原来的字符串的大小很可能小于拼接后的字符串的大小，那么这样的话，就会导致一旦忘记申请分配空间，就会导致内存的溢出。

     - 字符串在进行收缩的时候，内存空间会相应的收缩，而如果在进行字符串的切割的时候，没有对内存的空间进行一个重新分配，那么这部分多出来的空间就成为了内存泄露。

     而对于SDS，由于len属性和free属性的存在，对于修改字符串SDS实现了空间预分配和惰性空间释放两种策略：

     - 空间预分配：对字符串进行空间扩展的时候，扩展的内存比实际需要的多，这样可以减少连续执行字符串增长操作所需的内存重分配次数。
     - 惰性空间释放：对字符串进行缩短操作时，程序不立即使用内存重新分配来回收缩短后多余的字节，而是使用 free 属性将这些字节的数量记录下来，等待后续使用。（当然SDS也提供了相应的API，当我们有需要时，也可以手动释放这些未使用的空间。）

   - **二进制安全**

     因为C字符串以空字符作为字符串结束的标识，而对于一些二进制文件（如图片等），内容可能包括空字符串，因此C字符串无法正确存取；

     而所有 SDS 的API 都是以处理二进制的方式来处理 buf 里面的元素，并且 SDS 不是以空字符串来判断是否结束，而是以 len 属性表示的长度来判断字符串是否结束。

     SDS不是以空字符串来判断是否结束的

   - **兼容部分 C 字符串函数**

     虽然 SDS 是二进制安全的，但是一样遵从每个字符串都是以空字符串结尾的惯例，这样可以重用 C 语言库<string.h> 中的一部分函数。

   - **总结**

   | C 字符串                                   | SDS                                    |
   | ------------------------------------------ | -------------------------------------- |
   | 获取字符串长度的复杂度为O（N)              | 获取字符串长度的复杂度为O(1)           |
   | API 是不安全的，可能会造成缓冲区溢出       | API 是安全的，不会造成缓冲区溢出       |
   | 修改字符串长度N次必然需要执行N次内存重分配 | 修改字符串长度N次最多执行N次内存重分配 |
   | 只能保存文本数据                           | 可以保存二进制数据和文本文数据         |
   | 可以使用所有<String.h>库中的函数           | 可以使用一部分<string.h>库中的函数     |

   <hr>

   一般来说，SDS 除了保存数据库中的字符串值以外，SDS 还可以作为缓冲区（buffer）：包括 AOF 模块中的AOF缓冲区以及客户端状态中的输入缓冲区。后面在介绍Redis的持久化时会进行介绍。

##### LinkedList

1. 概述

   链表提供了高效的节点重排能力，以及顺序性的节点访问方式，并且可以通过增删节点来灵活地调整链表的长度。

   链表在Redis 中的应用非常广泛，比如**列表键的底层实现之一就是链表**。**当一个列表键包含了数量较多的元素，又或者列表中包含的元素都是比较长的字符串时，Redis 就会使用链表作为列表键的底层实现。**

2. 链表的数据结构

   每个链表节点使用一个 **listNode**结构表示（adlist.h/listNode）：

   ```c
   typedef struct listNode{
         struct listNode *prev;
         struct listNode * next;
         void * value;  
   }//链表是一个双向链表，Redis底层
   ```

   通过多个 listNode 结构就可以组成链表，这是一个双端链表，Redis还提供了操作链表的数据结构：

   ```c
   typedef struct list{
       //表头节点
       listNode  * head;
       //表尾节点
       listNode  * tail;
       //链表长度
       unsigned long len;
       //节点值复制函数
       void *(*dup) (void *ptr);
       //节点值释放函数
       void (*free) (void *ptr);
       //节点值对比函数
       int (*match)(void *ptr, void *key);
   }
   ```

3. 链表的特性
   - 双端：链表节点带有prev 和next 指针，获取某个节点的前置节点和后置节点的时间复杂度都是O（N），因为链表带有head指针和tail 指针，程序获取链表头结点和尾节点的时间复杂度为O(1)

   - 无环：表头节点的 prev 指针和表尾节点的next 都指向NULL，对立案表的访问时以NULL为截止

     无环，禁止有环的出现

   - 长度计数器：链表中存有记录链表长度的属性 len

   - 多态：链表节点使用 void\* 指针来保存节点值，并且可以通过list 结构的dup 、 free、 match三个属性为节点值设置类型特定函数。

##### HashTable

字典就是字典，还是链地址法解决冲突，还是过了threshold阀值 就会rehash

1. 概述

   字典，又称为符号表（symbol table）、关联数组（associative array）或映射（map），是一种用于保存键值对的抽象数据结构。　在字典中，一个键（key）可以和一个值（value）进行关联，字典中的每个键都是独一无二的。C 语言中没有内置这种数据结构的实现，所以字典依然是 Redis自己构建的。

   举个简单的例子：

   ```java
   redis > SET msg "hello world"
   OK
   ```

   创建这样的键值对（“msg”，“hello world”）在数据库中就是以字典的形式存储。

2. 字典定义

   Redis 的字典使用哈希表作为底层实现，哈希表结构定义：

   ```c
   typedef struct dictht {
      //哈希表数组
      dictEntry **table;
      //哈希表大小
      unsigned long size;
   
      //哈希表大小掩码，用于计算索引值
      unsigned long sizemask;
      //该哈希表已有节点的数量
      unsigned long used;
   }
   ```

   哈希表是由数组 table 组成，table 中每个元素都是指向 dict.h/dictEntry 结构，dictEntry 结构定义如下：

   ```c
   typedef struct dictEntry{
      //键
      void *key;
      //值
      union{
         void *val;
         uint64_tu64;
         int64_ts64;
      }
      struct dictEntry *next;
   
   }
   ```

   key 用来保存键，val 属性用来保存值，值可以是一个指针，也可以是uint64_t整数，也可以是int64_t整数。

   注意这里还有一个指向下一个哈希表节点的指针，我们知道哈希表最大的问题是存在哈希冲突，如何解决哈希冲突，有开放地址法和链地址法。这里采用的便是链地址法，通过next这个指针可以将多个哈希值相同的键值对连接在一起，用来解决**哈希冲突**。

   ![](../assets/redis 字典实现.png)

   为了封装一些额外功能（如根据不同类型的键值对来调用不同的hash函数、哈希表中内容较多或较少时进行扩容操作），字典的最终定义和结构如下：

   ```c
   typedef struct dict {
       // 类型特定函数
       dictType *type;
       // 私有数据
       void *privedata;
       // 哈希表，一个平时使用，另一个用于rehash时使用
       dictht  ht[2];
       // rehash 索引
       in trehashidx;
   }
   ```

   type 属性 和privdata 属性是针对不同类型的键值对，为创建多态字典而设置的。ht 属性是一个包含两个项（两个哈希表）的数组。

   用hash解决问题，必然要创建hash表记录key和对应的数组地址，其实有点像二级索引

   普通状态下的字典：

   ![](../assets/redis字典结构.png)

   ##### 补充：Redis计算哈希值和索引值方法如下：

   ```c
   #1、使用字典设置的哈希函数，计算键 key 的哈希值
   hash = dict->type->hashFunction(key);
   #2、使用哈希表的sizemask属性和第一步得到的哈希值，计算索引值
   index = hash & dict->ht[x].sizemask; 用hash值和 dict->ht[x].sizemask 得到的掩码进行计算
   ```

3. Rehash

   当哈希表保存的键值对太多或者太少时，就要通过 rerehash(重新散列）来对哈希表进行相应的扩展或者收缩。

   **因为本身就保存了两个hash表 ht[2] 所以 就是为了rehash准备的**

   有一定的装载因子，判定这个hashtabl是不是太满了

   **[具体步骤](https://www.cnblogs.com/jaycekon/p/6227442.html)：**

   - 如果执行扩展操作，会基于原哈希表创建一个大小等于 ht[0].used*2n 的哈希表（也就是每次扩展都是根据原哈希表已使用的空间扩大一倍创建另一个哈希表，都是2的n次幂）。相反如果执行的是收缩操作，每次收缩是根据已使用空间缩小一倍创建一个新的哈希表。

   - 重新利用上面的哈希算法，计算索引值，然后将键值对放到新的哈希表位置上。

     重新计算，因为扩容了，hash会重新计算，将所有键值迁移

   - 所有键值对都迁徙完毕后，释放原哈希表的内存空间。

   **触发扩容的条件：**

   - 服务器目前没有执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于1。

   - 服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于5。

     ps：负载因子 = 哈希表已保存节点数量 / 哈希表大小。

   

   ##### **渐近式 rehash**:

   什么叫渐进式 rehash？也就是说扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。如果保存在Redis中的键值对只有几个几十个，那么 rehash 操作可以瞬间完成，但是如果键值对有几百万，几千万甚至几亿，那么要一次性的进行 rehash，势必会造成Redis一段时间内不能进行别的操作。所以Redis采用渐进式 rehash,这样在进行渐进式rehash期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行增加操作，一定是在新的哈希表上进行的。

   渐进式rehash算法

##### SkipList

1. 简介

   跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其它节点的指针，从而达到快速访问节点的目的。具有如下性质：

   - 由很多层结构组成；

   - 每一层都是一个有序的链表，排列顺序为由高层到底层，都至少包含两个链表节点，分别是前面的head节点和后面的nil节点；

   - 最底层的链表包含了所有的元素；

   - 如果一个元素出现在某一层的链表中，那么在该层之下的链表也全都会出现；

   - 链表中的每个节点都包含两个指针，一个指向同一层的下一个链表节点，另一个指向下一层的同一个链表节点；

   其结构示意图如下：

   ![](../assets/redis 跳表结构.png)

2. 跳表定义

   redis中跳表节点定义如下：

   ```c
   typedef struct zskiplistNode{
   　　　//层，level 数组可以包含多个元素，每个元素都包含一个指向其他节点的指针。
        struct zskiplistLevel{
   　　　　//前进指针，用于指向表尾方向的前进指针
           struct zskiplistNode *forward;
   　　　　//跨度，用于记录两个节点之间的距离
           unsigned int span;
       } level[];
   　　//后退指针，用于从表尾向表头方向访问节点
       struct zskiplistNode *backward;
   　　//分值，跳跃表中的所有节点都按分值从小到大排序
       double score;
   　　//成员对象，指向一个字符串，这个字符串对象保存着一个SDS值
       robj *obj;//SDS 字符串值
   }
   ```

   多个跳跃表节点构成一个跳跃表：

   ```c
   typedef struct zskiplist{
        //表头节点和表尾节点
        structz skiplistNode *header, *tail;
        //表中节点的数量
        unsigned long length;
        //表中层数最大的节点的层数
        int level;
    
   }zskiplist;
   ```

3. 总结
   - 跳跃表是有序集合的底层实现之一；
   - 主要有zskiplist 和zskiplistNode两个结构组成；
   - 每个跳跃表节点的层高都是1至32之间的随机数；
   - 在同一个跳跃表中，多个节点可以包含相同的分值，但每个节点的对象必须是唯一的；
   - 节点按照分值的大小从大到小排序，如果分值相同，则按成员对象大小排序。

##### 整数集合

1. 简介

   整数集合（intset）是Redis用于保存整数值的集合抽象数据类型，

   它可以保存类型为int16_t、int32_t 或者int64_t 的整数值，并且保证集合中不会出现重复元素。

2. 定义

   ```c
   typedef struct intset{
        //编码方式
        uint32_t encoding;
        //集合包含的元素数量
        uint32_t length;
        //保存元素的数组
        int8_t contents[];
    
   }intset;
   ```

3. [升级](https://www.cnblogs.com/jaycekon/p/6277653.html)

4. 总结

   - 整数集合是集合建的底层实现之一；
   - 整数集合的底层实现为数组，这个数组以有序，无重复的范式保存集合元素，在有需要时，程序会根据新添加的元素类型改变这个数组的类型；
   - 升级操作为整数集合带来了操作上的灵活性，并且尽可能地节约了内存；
   - 整数集合只支持升级操作，不支持降级操作。

##### 补充：intset是如何实现有序无重复的？

##### 压缩列表

1. 简介

   **压缩列表是列表键和哈希键的底层实现之一**。当一个列表键只把汗少量列表项，并且每个列表项要么就是小整数，要么就是长度比较短的字符串，那么Redis 就会使用压缩列表来做列表键的底层实现。

   列表键本身就是为了节省内存而设定的

   压缩列表（ziplist）是Redis为了节省内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型数据结构，一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。

   **压缩列表的原理：压缩列表并不是对数据利用某种算法进行压缩，而是将数据按照一定规则编码在一块连续的内存区域，目的是节省内存。**

2. 压缩列表的组成

   ![](../assets/redis 压缩列表.png)

   压缩列表的总长，表尾距起始的距离，压缩列表结点数，压缩列表各节点，压缩列表尾部 

3. 总结

   - 压缩列表是一种为了节约内存而开发的顺序型数据结构；

   - **压缩列表被用作列表键和哈希键的底层实现之一**；

   - 压缩列表可以包含多个节点，每个节点可以保存一个字节数组或者整数值；

     确实有点hash表的感觉哈 多个结点，类似于数组 还不限定存储类型

   - 添加新节点到压缩列表，可能会引发连锁更新操作；

### 内部编码详解

##### redisObject

1. 简介

   Redis使用前面说的五大数据类型来表示键和值，每次在Redis数据库中创建一个键值对时，至少会创建两个对象，一个是键对象，一个是值对象，而Redis中的每个对象都是由 redisObject 结构来表示：

   ![](../assets/redisObject.png)

2. 定义

   ```c
   typedef struct redisObject{
        //类型
        unsigned type:4;
        //编码
        unsigned encoding:4;
        //指向底层数据结构的指针
        void *ptr;
        //引用计数
        int refcount;
        //记录最后一次被程序访问的时间
        unsigned lru:22;
    
   }robj
   ```

   可以通过如下命令来判断对象类型：

   ```shell
   >set str1 abcd
   OK
   >type str1
   string
   ```

   **注意：在Redis中，键总是一个字符串对象，而值可以是字符串、列表、集合等对象，**

   **所以我们通常说的键为字符串键，表示的是这个键对应的值为字符串对象，我们说一个键为集合键时，表示的是这个键对应的值为集合对象。**

##### [字符串对象](https://www.cnblogs.com/ysocean/p/9102811.html#_label1)

##### 列表对象

##### 哈希对象

##### 集合对象

##### 有序集合对象

##### **五大数据类型的应用场景**

SDS 二进制安全，不会出现空字符的情况

原来 单点登录 秒杀 都是通过redis实现的

# 应用场景 十分重要

##### String

对于string 数据类型，因为string 类型是二进制安全的，可以用来存放图片，视频等内容，另外由于Redis的高性能读写功能，而string类型的value也可以是数字，可以用作计数器（INCR,DECR），比如分布式环境中统计系统的在线人数，秒杀等。**总结：缓存、计数器、分布式锁。**

统计在线人数，排行榜，分布式锁，比如setnx 就是对一个String类型 赋值0/1

##### Hash

对于 hash 数据类型，value 存放的是键值对，比如可以做单点登录存放用户信息。

##### List

对于 list 数据类型，可以实现简单的消息队列，另外可以利用lrange命令，做基于redis的分页功能

##### Set

对于 set 数据类型，由于底层是字典实现的，查找元素特别快，另外set 数据类型不允许重复，利用这两个特性我们可以**进行全局去重**，比如在用户注册模块，判断用户名是否注册；

set都是 通过列表实现的

**另外就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能**。

##### ZSet 

zset 是有序集合

对于 zset 数据类型，有序的集合，可以做范围查找，排行榜应用，取 TOP N 操作等。

zipSet 压缩列表 还需要再看一下

# 五大结构的使用 ✅

### 字符串

##### 键值结构

​	key 为字符串，但value可以为字符串、整数、浮点数、二进制序列等，并且还可以存储一些特殊的内容，如json字符串、xml内容等。

​	value最大值不能超过512M，但为了保证性能，其大小一般不超过100k。

​	本身就是放在主存里，为了存取方便，你这512M...

![](../assets/字符串键值结构.png)

##### 使用场景

- 缓存
- 计数器（视频播放量、点赞、分享等）
- 分布式锁

##### 基础命令

通用部分：

1. get

   - Get key：(O(1)) 
   - Mget key1 key2 key3 ...：(O(n)) 批量获取key-value，原子操作，该命令可以节省大量网络传输时间（如果使用n 个get，则时间为n次网络时间+n次命令时间，命令时间很短，可以忽略不计，如果使用mget，则时间为1次网络时间+n次命令时间）
   - Getset key newValue：O(1)设置新的值并返回旧的值
   - Getrange key start end：O(1)获取字符串指定范围内的值

   一般这种耗时的操作 都会被放在从服务器上

2. Set (O(1))

   - Set key value：O(1) 不管 Key 是否存在，都设置
   - Setnx key value：O(1) key不存在，才设置
   - Set key value xx：O(1) key存在，才设置
   - Mset key1 value1 key2 value2 ...：(O(n))批量设置key-value
   - Set key index value：O(1)设置字符串指定位置的值

3. Del

独特部分：

1. Incr/decr ：O(1)

   Incr/decr key，key自增/自减1，如果key不存在，自增后get(key) = 1/-1

2. Incrby/decrby/Incrbyfloat ：O(1)

   Incrbt/decrbt key k，key自增/自减k，如果key不存在，自增后get(key) = k/-k

3. Append key value：O(1)

   将value 追加到旧的value上

4. Strlen key：O(1)

   返回字符串的长度，注意中文，如在utf-8情况下，每个中文占用两个字节。

##### 命令实战

1. 记录网站每个用户个人主页的访问量

```
incr userid:pageview	//单线程，无竞争，不会自增错误
```

2. 缓存视频的基本信息（数据源在mysql中）

```java
//伪代码实现
public VideoInfo getVideoInfo(long id){
    String redisKey = redisPrefix + id;
    VideoInfo videoInfo = redis.get(redisKey);
    if(videoInfo == null){
        videoInfo = mysql.get(redisKey);
        if(videoInfo != null){
            //序列化
            redis.set(redisKey, serialize(videoInfo));
        }
    }
    return videoInfo;
}
```

3. 实现一个分布式id生成器，具体需求如下：三个java服务每次获取到的id是自增的，而且它们是并发地来获取。

   ![](../assets/redis分布式id生成器.png)

   

##### 补充：单线程模型实现分布式id生成器

因为redis是单线程模型，所以不存在并发的问题，不存在线程竞争共享资源，所以redis很适合做分布式应用，实现一个分布式的id生成器

### 哈希

##### 键值结构

​	实际是key-(keys-values)

![](../assets/redis哈希键值结构.png)

​	可以将哈希结构中每一个key-value看做关系型数据库中的一行数据，key为主键。区别是哈希结构中属性的设置比较随意，没有关系型数据库中唯一、非空等要求。

##### 基础命令{ 2-7 hash(2) }

1. Hget key field：O(1)，获取hashKey对应的field的value；
   - Hmget
2. Hset key field value：O(1)，设置hashkey对应的field的value；
   - Hmset
3. Hdel key field：O(1)，删除hash key 对应的field；
4. Hexist 
5. hlen

##### 命令实战{ 2-7 hash(2) }

1. 记录网站每个用户个人主页的访问量

   ```
   hincrby user:1:info pageview count
   ```

2. 缓存视频的基本信息（数据源在mysql中）

### 列表

##### 键值结构

![](../assets/redis列表结构.png)

​	特点：

- 有序：根据插入顺序排序
- 可重复
- 左右两边插入弹出

##### 基础命令{ 2-8 list(1) }

##### 实战{ 2-9 list(2) }

### 集合

##### 键值结构

![](../assets/redis 集合.png)

​	特点：

- 无序
- 不可重复
- 可以实现集合间的操作，如交集、并集

##### 基础命令{ 2-10 set }

##### 实战{ 2-10 set }

### 有序集合

##### 键值结构

![](../assets/redis有序集合.png)

##### 基础命令{ 2-11 zset }

##### 实战{ 2-11 zset }



# Redis的六大特性

##### 慢查询 找到系统性能瓶颈的命令

##### PipeLine 流水线节省IO时间

### 慢查询

​	慢查询指的是可以帮我们找到系统性能瓶颈的命令

##### 生命周期

![](../assets/redis 命令生命周期.png)

注意：

1. 慢查询发生在第三阶段；
2. 客户端超时不一定是慢查询，但慢查询是客户端超时的一个可能因素；

这个慢查询应该和TCP的拥塞控制中的慢查询类型

先线性增长，达到一定阀值后进入慢查询状态，所谓慢查询就是 命令数量逐个递增，比如发送10个包通过计算时间没有拥塞，拥塞是整个系统的拥塞，不是点对点传输的过快，或说流量超出

##### 两个配置{ 4-2 4:50}

##### 三个命令{ 4-2 6:55}

##### 运维经验{ 4-2 7:25}



### Pipeline

这种模式，下一次请求必须得等第一次请求响应回来之后才可以，因为redis是单线程的，按部就班，一步一步来。
而pipeline管道改变了这种请求模式，客户端可以一次发送多个命令，无须等待服务器的返回，
请求，请求，请求，响应，响应，响应.

一次发送多个命令，无需等待服务器返回

这种模式这就大大减少了影响性能的关键因素-网络往返时间.

其实就是 TCP连续ARQ协议或说滑动窗口的感觉

重要说明: 使用管道发送命令时，服务器将被迫回复一个队列答复，占用很多内存。所以，如果你需要发送大量的命令，
最好是把他们按照合理数量分批次的处理，例如10K的命令，读回复，然后再发送另一个10k的命令，等等。这样速度几
乎是相同的，但是在回复这10k命令队列需要非常大量的内存用来组织返回数据内容。
Jedis jedis = poolFactory.getjedisResourcePool().getResource();
Pipeline pl = jedis.pipelined();
Pipeline 的特点：
1、Pipeline 实现的原理是队列，而队列的原理是时先进先出，这样就保证数据的顺序性

​	与linux的管道类似，实现流水线功能，可以帮助提高客户端效率。因为redis基于请求/响应模型，单个请求处理需要一一应答，pipeLine批量执行命令，节省多次io往返时间。以上的设想是建立在所要执行的指令之间没有依赖性，如果有依赖，建议使用pipeLine分批次发送，对建议放在不同批内

pipline批量执行命令，但是一定要注意命令之间不可有依赖

如果所要执行的指令之间有依赖，比如后一步需要基于前一步的结果，那么pipeline不是一个好选择

##### 什么是流水线

​	也就是说不能一个redis请求来了 就tcp连接一次，然后断开

​	其实是帮助我们将命令批量打包，传送给redis服务器，再批量返回结果。一次这样的操作就是流水线操作。

- 一条命令发向服务器经过计算到最后获得结果，总共耗时为 网络传输时间 + 计算时间；

- N条命令发向服务器经过计算到最后获得结果，总共耗时为 n* 网络传输时间 + n*计算时间；

- 通过流水线技术打包，N条命令发向服务器经过计算到最后获得结果，总共耗时为 1* 网络传输时间 + n*计算时间；

  redis服务内部的命令执行时间很短（微秒级别），主要是网络传输时间耗时常，批量打包之后可以显著提升效率。

<hr>

##### Pipline在jedis中实现{ 4-3 6:25}

<hr>

##### 与原生操作(m操作)对比

- 原生m操作是原子性的，pipline是非原子性的，但返回结果是按照顺序返回的，当redis服务器收到很多请求时，其流程示意如下：

  非原子性的意思是，不会整个pipeline要么都做要么全都不做

  ![](../assets/redisPipline.png)

<hr>

##### 使用建议

- 注意每次pipline携带的数据量，大量操作可以拆分，比如10000条命令可以拆分成10 个1000进行发送

- pipline每次只能作用在一个redis节点上

  pipeline只能基于点对点 其实类似TCP pipeline 连续ARQ协议 那种感觉

<hr>
##### 补充：Pipeline是非原子性的



### 发布订阅

​	可以帮助我们使用redis实现发布订阅功能。

##### 什么是发布订阅模式

​	在软件架构中，**发布订阅**是一种消息范式，消息的发送者（称为发布者）不会将消息直接发送给特定的接收者（称为订阅者）。而是将发布的消息分为不同的类别，无需了解哪些订阅者（如果有的话）可能存在。同样的，订阅者可以表达对一个或多个类别的兴趣，只接收感兴趣的消息，无需了解哪些发布者（如果有的话）存在。

##### 模型

​	其模型结构如下：

![](../assets/redis发布订阅模型.png)

​	该模式与生产者消费者模型相似。主要角色有发布者（publisher）、订阅者（subscriber）、频道（channel）。

​	注意点：

- 发布者发布信息之后，所有订阅者都可以收到信息；

- 每个订阅者可以订阅多个频道； 是一个多对多的关系
- 消息无法堆积，订阅者不可以查看以往消息。
- 与消息队列区别：消息队列中，发布者发布消息后，由订阅者来抢消息，而不是都收到消息；并且redis并没有实现消息队列，需要手动加锁来实现；

##### API { 4-4 4:05}

<hr>

### Bitmap

​	俗称为“位图”，所谓的BitMap就是用一个bit位来标记某个元素所对应的value，而key即是该元素，由于BitMap使用了bit位来存储数据，因此可以大大节省存储空间。

##### 基本思想

​	这此我用一个简单的例子来详细介绍BitMap算法的原理。假设我们要对0-7内的5个元素(4,7,2,5,3)进行排序(这里假设元素没有重复)。我们可以使用BitMap算法达到排序目的。要表示8个数，我们需要8个byte。

　　1.首先我们开辟一个字节(8byte)的空间，将这些空间的所有的byte位都设置为0

　　2.然后便利这5个元素，第一个元素是4，因为下边从0开始，因此我们把第五个字节的值设置为1

　　3.然后再处理剩下的四个元素，最终8个字节的状态如下图

![](../assets/redisBitMap 基本思想.png)

　4.现在我们遍历一次bytes区域，把值为1的byte的位置输出(2,3,4,5,7)，这样便达到了排序的目的

##### 位图操作

​	即redis中可以对数据存储的二进制序列进行操作，例如：

```java
set hello big	//存储一个big字符串
```

![](../assets/redisBitMap.png)

​	这样我们可以直接获取该二进制序列中的指定位置的0和1值。

```java
getbit hello 0	//(integer)0
```

##### API{4-5 2:25}

##### 实战

1. 独立用户统计，使用set和bitMap所需的存储空间对比（注意bitmap的位数是如何出来的，第一位代表0，第二位代表1，完全是用位来计数，固100,000,000独立用户需要至少100,000,000位，此处不需要再通过二进制进行换算）

   ![](../assets/redis 独立用户统计.png)

   可以看到，在数据量很大时，bitMap十分节省内存。但数据量较小时，如10万用户，bitmap所需要的空间反而更大。

##### 使用经验

- 注意setbit 时的偏移量，可能有较大耗时
- type = String，最大512MB，如果依旧不够数据存放，则需要进行拆分。

<hr>

### HyperLogLog{ 4-6 }

​	更加极端的一种节省内存方案的数据结构，可以用极小的内存来实现独立用户的统计。

<hr>

### GEO{ 4-7 }

​	Redis3.2提供的地理定位功能

<hr>
# Redis的过期策略

##### 定时过期

每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。

# Redis持久化的取舍和选择 ✅

### 持久化相关概念

​	redis 所有数据保存在内存中，对数据的更新将异步保存到磁盘上，重启服务器时，redis 会从硬盘中将数据恢复到内存上。

​	当前主流的持久化实现方式有：

- 快照：保存某个时间点的全量数据快照。<font color='gray'>关于指定数据集合的一个完全可用拷贝，该拷贝包括相应数据在某个时间点（拷贝开始的时间点）的映像</font>。

  目前mysql的dump和redis RDB都是使用快照技术；

  redis的RDB也是快照技术，也怪不得Redis主从复制的时候传的是RDB了

- 写日志：对任何数据的更新都记录在日志中，某时某刻要恢复数据时，就按照存储的日志上记录的流程重新走一遍。目前mysql的binlog和redis的AOF 都是使用该种技术。

  比如主从复制开始前的缓存命令

### RDB（Redis DataBase）

​	rdb即快照技术，保存某个时间点的全量数据快照。

##### RDB流程：

rdb过程通过命令启动，其过程如下所示：

![](../assets/redisRDB.png)

##### 触发RDB的三种方式

​	三种方式分别为：save（同步）、bgsave（异步）、自动生成

##### save

通过save命令启动RDB，过程如下：

![](../assets/redis-RDB-save.png)

此时用户访问状态如下：

![](../assets/redis-rdb-save2.png)

注：

- **但该命令是同步命令，会让当前请求的其它命令先阻塞，在数据量较大的情况下会严重影响用户体验；**
- 文件策略：如果硬盘中存在旧的RDB文件，则会进行替换；
- 时间复杂度：O(n)。

同步命令，就会让当前请求的命令阻塞..所以这叫同步命令

##### bgsave

1. 简介

   在收到bgsave命令后，redis服务器会fork一个新的进程去创建并存储rdb文件，并立即恢复对客户端的服务，在客户端，我们可以使用`lastSave`指令查看save操作是否成功，该指令记录了上一次执行 save 或者 bgsave 的执行时间。

2. bgsave启动流程

   通过bgsave命令启动RDB，过程如下：

   ![](../assets/redis-RDB-bgsave.png)

   此时用户访问状态如下：

   ![](../assets/redis-rdb-bgsave2.png)

   注意：

   - 在收到bgsave命令后，redis服务器会fork一个新的进程去创建并存储rdb文件，在大多数情况下，fork指令会很快速完成任务，极少数情况下fork指令也会影响到redis主进程；
   - 时间复杂度：O(n)；
   - 文件策略：如果硬盘中存在旧的RDB文件，则会进行替换；




##### 关于fork()命令

一个进程，包括代码、数据和分配给进程的资源。fork（）函数通过系统调用创建一个与原来进程几乎完全相同的进程，也就是两个进程可以做完全相同的事，但如果初始参数或者传入的变量不同，两个进程也可以做不同的事。
 　 一个进程调用fork（）函数后，系统先给新的进程分配资源，例如存储数据和代码的空间。然后把原来的进程的所有值都复制到新的新进程中，只有少数值与原来的进程的值不同。相当于克隆了一个自己。

在fork函数执行完毕后，如果创建新进程成功，则出现两个进程，一个是子进程，一个是父进程。在子进程中，fork函数返回0，在父进程中，fork返回新创建子进程的进程ID。我们可以通过fork返回的值来判断当前进程是子进程还是父进程。

fork函数是值复制，所以子父进程相应变量的地址是不同的

![13CD825C-0234-4739-BC9D-A5B55A8E3B5F](../asserts/13CD825C-0234-4739-BC9D-A5B55A8E3B5F.png)

<https://www.jianshu.com/p/484af1700176>

1.bgsave的底层原理解析：

bgsave命令的详细流程图如下：

![](../assets/redis bgsave原理.png)

​	对该流程图的解释：

- 同一时间只能有一个子进程执行持久化命令，在执行期间redis服务器接收到新的持久化命令会拒绝执行；

- 在redis调用rdbSaveBackground函数时，本质是调用了操作系统的fork函数，在linux系统下，fork函数开辟新线程实现了copy-on-write，即写实复制。传统方式下，fork函数开辟新线程时，直接把所有资源复制给子进程，这种方法实现简单，但效率低下，而且复制的资源可能对子进程毫无用处。而linux为了降低创建子进程的成本，改进fork实现方式，

  当父进程创建子进程时，父进程值为子进程创建虚拟空间，父子进程使用的是相同的物理空间，只有变量发生更改时，才会为子进程分配独立的空间。



- save与bgsave的对比

  ![](../assets/redis-rdb-save-bgsave.png)

##### 自动生成RDB文件

其流程如下：通过在配置文件中指定保存规则来自动生成RDB文件进行存储。

![](../assets/redis-rdb-自动保存.png)

但不建议这样做，一是难以控制，并且在改变较为频繁地系统中十分消耗资源。

除了上述三个save参数，还有一些相关参数需要关注：

- Rdbcompression，默认为yes，建议设置为no，因为redis本身就属于cpu密集型应用程序，相比于硬盘空间，cpu计算时间更宝贵。
- Stop-writes-on-bgsave-errors，默认为yes
- **额外触发方式：进行全量复制（主从复制）操作时、进行debug reload操作时、进行shutdown操作时**。

##### RDB的缺点

- 耗时、耗性能：内存数据的全量同步，数据量大会由于I/O而严重影响性能；

- 不可控，容易丢失数据，可能因为redis挂掉而丢失从当前至最近一次快照期间的数据。

  ![](../assets/redis-rdb-丢失数据.png)

### AOF（Append Only File）

##### AOF运行原理

​	其实有点像，Mysql按SQL命令进行记录

​	对数据库中每次执行的操作，都采用一个日志文件将其记录，当发生宕机或其它需要数据恢复情况时，再从日志文件中读取操作记录，从而将数据恢复。具体流程（创建、恢复）如下：

![](../assets/redis-aof-创建.png)

![](../assets/redis-aof-恢复.png)

##### AOF运行流程

​	aof的运行流程图如下：

​	![](../assets/redis aof运行流程图.png)

##### AOF的三种策略

​	redis 在执行写命令时实际不是直接将记录写在文件系统中，而是先写在写命令的缓冲区中，缓冲区会根据指定的策略来将缓冲刷新到磁盘。这些策略分别为：always、everysec、no。

- Aways：是指每条写命令都会执行 fsync 命令，将缓冲数据写到硬盘当中，流程如下：

  ![](../assets/redis-aof-三种策略-always.png)

- Everysec：每秒执行一次 fsync 命令，将缓冲数据写到硬盘当中。这样兼顾了硬盘性能和安全性，但同样有可能因为宕机而丢失一秒钟的操作数据。**是aof默认执行策略**。

- No：由操作系统决定什么时候执行 fsync 命令。

三种策略的对比：

![](../assets/redis-aof-三种策略-优缺点对比.png)

通常情况下，默认使用第二种（everysec）策略。

##### AOF重写

​	AOF策略可以将每条命令都写入到AOF文件当中，但存在着一个问题，随着并发量增大、时间推移，AOF文件也会增大。这样就会造成很多问题，如使用AOF文件恢复时，过程会十分慢。

​	由此redis提供了AOF重写来解决上述问题。AOF重写的目标就是将过期的、重复的、没有用的和一些可以优化的命令进行化简，从而降低AOF文件大小，从而减小磁盘占用量、加快磁盘恢复速度。如以下重写命令所示：

![](../assets/redis-aof-重写.png)

##### AOF重写的两种实现方式

两种方式分别为 bgrewriteaof命令 和 aof重写配置。

- Bgrewriteaof，该命令会让redis开出一个新的子进程去重写aof文件，注意这里重写aof文件是对redis数据库中的操作记录进行回溯和化简，而不是真的对原本的aof文件进行化简。其过程如下：

  ![](../assets/redis-aof-bgrewriteaof.png)

- aof重写配置

  ![](../assets/redis-aof-重写配置.png)

  当同时满足如下两个条件时，触发aof自动重写：

  - Aof_current_size > auto-aof-rewrite-min-size
  - (Aof_current_size - aof_base_size)/aof_base_size > auto-aof-rewrite-percentage

1. aof重写流程

   ![](../assets/aof 重写流程.png)

### RDB和AOF的抉择

![](../assets/rdb 与aof.png)

### RDB-AOF混合持久化方式

​	redis4.0之后推出了RDB-AOF混合化持久方式，即用RDB做全量备份，用AOF做增量备份，并且已经将该配置作为默认配置来使用。

​	在该种模式下，子进程在进行持久化时，会通过管道读取父进程中的增量数据并缓存下来，在以rdb的形式保存全量数据时，也会从管道读取数据，不会造成管道的阻塞。也就是说，aof文件的前半段是rdb格式的全量数据，后半段是aof格式的增量数据。

​	总结来说，该种方式会使用bgsave做镜像持久化，使用aof做增量持久化。

### redis 的数据恢复流程

![](../assets/redis 的数据恢复流程.png)

# 主从复制

### 简介

​	redis主从同步结构图如下：

![](../assets/redis主从同步原理.png)

​	图中Master和Slave分别代表了一个个独立的redis server实例，Master用于写操作，Slave则用于进行读操作。（并且Keys等耗时的操作也放在Slave服务器上）

定期的备份操作也是选择一个slave区完成。这样可以最大程度发挥出redis的性能。

为了实现数据的弱一致性和最终一致性，我们不需要实时保证Master和Slave的数据是实时同步的。但是在过了一段时间之后，它们的数据是趋于同步的，这就是所谓的最终一致性。

​	Redis可以使用主从同步和从从同步。第一次同步时，主节点做一次bgsave，同时，将后续的内存操作记录到内存的buffer里面去。待完成后，将rdb文件全量同步到从节点中；从节点接收后，就将rdb文件的镜像加载到内存中，加载完成后，再通知主节点，将期间的操作记录及增量数据同步到从节点。

### 同步过程 ✅

##### 全量同步过程

一般是第一次同步的时候

- slave 发送 sync 命令到Master；
- Master 启动一个后台进程，将 redis 中的数据快照保存到文件中，即bgsave；
- Master 将保存数据快照期间接收到的写命令缓存起来，即将增量数据先缓存起来；
- Master完成写文件操作后（即写一个RDB文件），将该文件发送给 Slave；（一个RDB文件）
- Slave 接收到文件后就将文件保存到磁盘中并替换原有的文件（RDB文件？），并加载文件到内存中，去恢复数据快照；
- 当 slave 完成恢复数据快照后，Master 就将这期间收集的增量写命令发送给 slave 端，进行回放。

​	全量同步完成后，所有的写操作都是在 Master 上进行，所有的读操作都是在 Slave 上进行的。

后续 master 收到的写命令都会通过开始建立的连接发送给 slave，当cache的写操作都发给slave进行回放后，后续master收到的写操作，都会通过连接发送给slave。



当 master 和 slave 的连接断开时 slave 可以自动重新建立连接。如果 master 同时收到多个 slave 发来的同步连接命令，只会启动一个进程来写数据库镜像，**只启动一个文件写**，然后发送给所有 slave。



##### 增量同步过程

- Master 接收到用户的操作指令，判断是否需要传播到 Slave；
- 将该操作记录到AOF文件中；
- 将操作传播到其它的 Slave 中，主要有两步处理：
  - 对齐主从库，确保从数据库是该操作对应的数据库；
  - Master 向响应缓存中写入命令。
- Master 将响应缓存中的数据发送给 Slave。



### Redis Sentinel(哨兵机制)

##### 简介

​	上述主从模式存在一个弊端，即不存在高可用性，当 master 挂掉之后，redis服务器将不能对外提供写入操作。

​	由此引入 Redis Sentinel， 即 Redis 哨兵机制，主要用来解决主从同步Master宕机后的主从切换问题，是 Redis 官方提供的Redis集群管理工具。其本身也是一个独立运行的进程，它能监控多个 Master-Slave 集群，发现 Master 宕机之后能进行自动切换，主要功能有如下几点：

否则当一个master挂了后，我们要人工手动重启，并且还会导致系统不可用

- 监控（Monitoring）：检查主从服务器是否运行正常；

- 提醒（Notification）：当redis服务器发生故障时，Sentinel通过 API 向管理员或其它应用程序发送故障通知。

- 自动故障迁移：当一个 Master 不能正常工作时，Sentinel会开启一次自动故障迁移操作，它会将失效的主服务器下的一个从服务器自动升级为 Master。

  
  
  

##### 自动故障迁移如何实现？

哨兵修改配置文件来的

并让其它的 Slave 改为复制当前新生成的 Master。当客户端试图连接已经失效的 Master 时，集群也会向客户端返回新的 Master 的地址，使得集群可以使用新的 Master 代替失效的 Master。



​	Redis Sentinel是一个分布式的系统，可以在一个架构中运行多个 Sentinel 进程，这些进程使用流言协议(Gossip Protocal)来接受主服务器是否下线的信息，并使用投票协议来决定是否执行自动故障迁移，以及选择哪一个 Slave 服务器作为新的主服务器。与ZooKeeper比较类似。

##### 补充：多个哨兵，有时候一个哨兵监控并不靠谱



# Redis集群

流言协议 是Redis集群的基础

### 简介

​	集群技术是构造高性能网站的重要手段，在网站承受高并发访问压力的同时，还需要从海量数据中查询出满足条件的数据并快速响应，应怎么应对？

​	采用分片技术 即水平分表，用hash计算出数据所在服务器位置，以此来降流：按照某种规则对海量数据进行划分，分散存储在多个redis节点上。

​	redis cluster采用无中心结构，每个节点保存数据和整个集群的状态，每个节点都和其它所有节点连接，节点之间使用Gossip协议去传播信息并发现新的节点。



##### Gossip Protocal 流言协议

##### 流言协议是Redis集群的基础

​	Gossip Protocal，即流言协议，又被称作反熵协议。熵是统计学中的概念，表示杂乱无章，反熵即为在杂乱无章中寻求一致。这也充分反映了Gossip Protocal的特点：

- 在一个有界网络中，每个节点都随机与其它节点进行通信，经过一番杂乱无章的通信之后，最终，所有的节点状态都会达成一致。每个节点可能知道其它的所有节点，也可能仅知道几个邻居节点；
- 该协议需要种子节点，种子节点定期随机向其它节点发送节点列表和需要传播的信息。任何新加入的节点就在这种模式下很快地被全网所知道；
- 不能保证信息一定会传递给所有节点，但是最终会趋于一致。

​	在火热的区块链技术中，fabric使用的就是流言协议，来进行点对点的多中心化或者去中心化通信。

去中心化通信，每一个节点都知道所有节点或者临近节点的信息，并最终趋于一致

该协议需要种子结点，定期向其他节点，发送列表和需要传播的信息，任何新加入的节点就在这种模式下，可以很快被知道

### 一致性哈希算法

### 实现原理

​	redis集群的目标是将大量的数据分散放置到不同的redis节点中，具体如何分散？

​	通常的做法是获取key的哈希值，根据节点数来求模。但常规的按照哈希划分的方法无法实现节点的动态增减。为了解决该问题，redis引入了一致性哈希算法。

​	**一致性哈希算法：**对2^32取模，将哈希值空间组织成虚拟的圆环。

​	一致性哈希算法依旧是取模算法，但之前的哈希算法是对服务器数量取模，而一致性哈希算法是对2^32。简单来说，就是将整个哈希空间组织成一个虚拟的圆环，整个哈希环如下：

![](../assets/哈希环.png)

​	整个空间会按照顺时针方向组织。圆环的正上方代表0，0右边的第一个点代表1，以此类推，直到2^32 - 1。

​	下一步就是将各个服务器使用一致性哈希函数去计算出各自的hash值并添加到圆环上，具体计算数据可以使用主机的 ip 或者主机名，如下图所示：

​	具体数值可以用主机ip或者主机名，然后使用一致性hash函数，（可以规定hash值的长度），然后将redis节点映射在环上

![](../assets/哈希环2.png)

​	将服务器映射到哈希环上后，会对数据采用同样的哈希算法，将其映射到哈希环上，但基本不可能正好映射到服务器上，于是变回采用顺时针寻找服务器的方法，找到顺时针方向上距离自己最近的服务器，并将数据存储在该服务器上。如上图所示。具体优点如下：

- 可以有效应对服务器宕机情况，比如上图中，cache服务器5宕机，此时原本应由cache服务器5存储的数据就会直接找到cache服务器4来存储数据。 除了服务器4，别的服务器并不会因为服务器5的宕机而受到影响。

- 这样也可以方便地在服务器集群中新增服务器节点，这样受影响的也只有新增服务器相邻的两个服务器。

  这样可以方便在服务器集群中新增服务器节点，这样受影响的，也只有新增服务器相邻的两个服务器，一个少了，一个多了，来的信息/数据 通过hash运算 顺时针找到离自己最近的服务器

### 环数据倾斜

​	但在服务器过少时，也可能出现环数据倾斜的情况，如下图所示：

![](../assets/哈希环数据倾斜.png)

​	即因为服务器节点过少，经过一致性哈希算法之后导致其在哈希环上分布不均匀，从而产生数据倾斜问题，即大多数数据集中到了一台服务器上。

​	为了解决这个问题，可以引入"虚拟机器"的概念，也就是说，一台机器需要在环上映射出多个位置。比如我们用机器的ip来hash，那么我们可以在主机名或者主机ip后面加几个编号，形如ip_1, ip_2, ip_3... 这样就实现了一台物理机器映射出了多个虚拟机器的编号。

​	一台物理机器映射多个虚拟机器编号，进而可以保证数据相对均匀的分布在物理机器上，在实际应用中，通常将虚拟节点设置为32 甚至更大

​	数据首先映射到"虚拟机器"上，再从"虚拟机器"映射到物理机器上。因为虚拟机器可以很多，在环上均匀分布，从而保证数据相对均匀地分布在物理机器上。在实际应用中，通常将虚拟节点设置为32，甚至更大。

​	结合redis集群技术，我们还可以在期间引入主从同步、哨兵技术来进一步确保集群的高可用性。这也是主流应用的做法。

# Redis过期策略

我们都知道，Redis是key-value数据库，我们可以设置Redis中缓存的key的过期时间。Redis的过期策略就是指当Redis中缓存的key过期了，Redis如何处理。

过期策略通常有以下三种：

- 定时过期：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。
- 惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。
- 定期过期：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。
  (expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。)

Redis中同时使用了惰性过期和定期过期两种过期策略。



# Redis缓存淘汰策略

Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。

- noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。
- allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。
- allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。
- volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。
- volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。
- volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。

# 面试题汇总

### 为什么Redis能这么快？

​	首先Redis的每秒查询次数(QPS, query per second)能达到 100, 000+，其能达到这么快的原因，主要如下：

- 完全基于内存，绝大部分请求是纯粹的内存操作，执行效率高；
- 数据结构简单，对数据操作也简单。因为redis不使用表，redis也不要求对数据进行强制关联，其存储结构就是键值对，运行效率要比关系型数据库高出一个量级；
- 采用单线程处理网络请求（redis本身不是单线程），单线程也可以处理高并发请求，想多核可启动多实例。这样就避免了频繁地对锁资源进行争夺，提高了效率；
- 使用多路 I/O 复用模型，非阻塞I/O。p6:52

### 海量数据查询固定前缀key

两种方式：

- 使用keys指令(不建议)，用法为`keys pattern`，查找所有符合给定pattern的keys，如`keys k1*`即查找所有以k1开头的key。但该方法存在问题，即keys指令会一次性返回所有符合条件的key，而且由于redis在接受服务端请求方面是单线程，因此在数据量过大的情况下有可能会造成服务卡顿，对于内存的消耗和redis服务器都是隐患。

- scan指令，每次迭代前需要获得上一次迭代的游标，延续之前的迭代过程

  

- 使用`scan`指令，该指令可以无阻塞的提取出 Key列表，用法如下`scan cursor [Match pattern][Count count]`，执行时只返回少量元素，所以可用于生产环境。具体细节如下：

  - scan是基于游标的迭代器，每次迭代前需要获得上一次迭代的游标，延续之前的迭代过程；
  - 以0作为游标开始一次新的迭代，直到命令返回游标0完成一次遍历；
  - 不保证每次执行都返回某个给定数量的元素，支持模糊查询；
  - 一次返回的数量不可控，只是大概率符合count参数；
  - 返回的数据中可能有重复数据（不是完全按照游标从前向后推进，上一次游标可能比当前的还大），需要在外部程序中去重（如java中的hashSet）。

  实例：`scan 0 match k1* count 10`，该句的含义为从0开始迭代，匹配以 `k1` 为开头的key，每次返回10条。

  根据上次的游标来查询信息，是非阻塞实现的，并且不保证某次执行都返回某个给定数量的元素，支持模糊查询，并且可能回重复，所以需要外部去重

### 如何实现分布式锁

##### 分布式锁

​	分布式锁是控制分布式系统或不同系统之间访问共享资源的一种锁的实现。如果不同系统或同一个系统的不同主机之间共享了某个资源时，往往需要互斥来防止彼此干扰，进而保证一致性。

​	分布式锁需要解决的问题如下：



分布式锁，不同系统访问共享资源，其实和多个线程，多个进程有共享资源差不多

##### 特点：

- 互斥访问，即任何一个时刻只能有一个客户端获取锁，不能同时被多个客户端获取到锁；
- 安全性，锁只能由持有该锁的客户端释放，不能被其他客户端释放；
- 死锁，获取锁的客户端，因为某些原因宕机，未能释放锁，其他客户端再也无法获取到该锁而导致了死锁，需要有机制来避免该问题的发生；
- 容错，当部分节点宕机时，客户端仍然能获取锁和释放锁。

##### 互斥访问，安全性 死锁和容错 

##### 如何通过redis实现分布式锁

通过redis的`SETNX key value`指令

通过redis的`SETNX key value`指令：如果key不存在，则创建并赋值。

- 时间复杂度为O(1)；
- 设置成功，返回值1，设置失败，返回值0；
- 操作是**原子性**的。

​	在实际使用`setnx`实现分布式锁的过程中，线程先尝试通过`setnx`对某个key设值，如果成功，代表此时没有别的线程占用资源，该线程可以抢夺资源；如果设值失败，代表现在正有别的线程占用资源，该线程需要等待，直至`setnx`指令成功。

//阻塞式的 

​	但由此也引出了一个问题，`setnx`指令是让key长久存在，如何设置key的过期时间？有两种方式：

- 第一种(早期的实现方式，可能会出现问题，现在不推荐)，通过`expire`指令，即`expire key seconds`：设置key的生存时间，当key过期时，会被自动删除。

  实际在java代码中的操作如下：

  ```java
  RedisService redisService = SpringUtils.getBean(RedisService.class);
  long status = redisService.setnx(key, "1");//RedisService 是个提供服务的Bean
  
  if(status == 1){
  		redisService.expire(key, expire);
  		// 执行独占资源代码
  		doOccupiedWork();
  }
  ```

  但上述代码存在问题，即如果某线程执行完`long status = redisService.setnx(key, "1")`代码后就直接挂了，来不及执行`doOccupiedWork()`代码，此时资源就会被一直独占，别的线程无法再获取资源。出现该问题主要是由于操作的**原子性得不到满足**，即虽然`setnx`和`expire`都是原子性的，但他们两的组合并不是原子性的，可能会存在上述问题。

  但是会有问题

  那就将两个命令结合起来，形成一个原子操作，不可分割 

  ##### 补充：

  setnx key对

- 第二种，自redis 2.6.12版本之后，就可以使用`SET key value [EX seconds][PX milliseSeconds] [NX|XX]`操作来将之前两步操作融合为一个原子操作。其解析如下：

  - EX seconds：设置键的过期时间为seconds秒；
  - PX milliseSeconds：设置键的过期时间为 milliseSeconds 毫秒；
  - NX：只有键不存在时，才对键进行设置操作；
  - XX：只有键存在时，才对键进行设置操作；
  - SET操作成功，返回OK，失败则返回nil；
  - value值可以设置成当前线程的id，用来标识哪个线程占用了该资源。

  实际在java代码中的操作如下：

  ```java
  RedisService redisService = SpringUtils.getBean(RedisService.class);
  String result = redisService.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime);
  
  if("OK".equals(result)){
  		// 执行独占资源代码
  		doOccupiedWork();
  }
  ```

  注：大量key同时过期的注意事项：如果同一时间内有大量key集中过期，清除大量key很耗时，可能会出现卡顿现象。解决方案：在设置key的过期时间时，给每个key加上随机值。

### 如何实现异步队列

- 通过redis 中的`list`数据结构实现

  使用 list 作为队列，`rpush`生产消息，`lpop`消费消息。但**存在问题**，即可能出现没有等待队列中有值就直接进行`lpop`操作，弥补方式为在实际代码中引入sleep机制去调用`lpop`重试。

  但如果不使用 sleep 机制，可以使用`blpop key[key...] timeout`指令实现，该指令没取到值时会阻塞直到队列中有消息或者超时。但**依旧存在问题**，即生产者生产出的消息只能提供给一个消费者消费。

- 使用瑞士军刀redis中的六大特性之一：pub/sub发布订阅模式实现异步队列。

  发送者(pub)可以发送消息，订阅者(sub)可以接收消息。订阅者可以订阅任意数量的频道（topic）。

  其模型结构如下：

  ![](../assets/redis发布订阅模型.png)

  具体操作如下：

  - 客户端1订阅频道"topic1"

    ```shell
    >subscribe topic1
    ```

  - 客户端2订阅频道"topic1"

  - ```
    >subscribe topic1
    ```

  - 客户端3订阅频道"topic2"

    ```
    >subscribe topic2
    ```

  - 客户端4在频道发布消息

    ```
    >publish topic1 "Hello"		# 此时客户端1和客户端2会受到消息，而客户端3不会收到消息
    ```

  但该方式依旧存在缺点，即消息的发布是无状态的，无法保证可达的，对发布者来说，消息是即发即失的。
  
  <font color='red'>面试官不问不要答后面部分</font>如果某个消费者在生产者发布消息的时候下线，重新上线是接受不到消息的。针对该问题，可以使用专业的消息队列来实现，如kafka。