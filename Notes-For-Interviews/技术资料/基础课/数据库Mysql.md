# 数据库理论部分

数据库：

SQL

理论部分

MYSQL

REDIS

这四个大板块 

##### 理论部分：

- 四大范式（前三个重要）✅
- 数据库事务的特性 ACID ✅
- 数据库事务的四大隔离级别以及出现的问题 ✅
- MVCC，多版本并发控制，是提交读和可重复读的根本
- 数据库的锁（读写，共享排他，悲观乐观） ✅
- SQL与NOSQL，SQL其实就是结构化语言，也是一种事务 ✅

##### MySQL部分：

- 数据库索引及优化 ✅ 优化就是选什么字段用索引，然后什么时候索引会失效不能这么用
- 索引的底层实现：B-Tree B+Tree Hash BitMap这些底层实现结构 ✅
- 查询优化？
- 数据库 存储引擎层InnoDB和MyIsasm，服务层其实就是做个接口 ✅
- 数据库与分布式：主从复制，水平切分与垂直切分，日志 这是分布式数据库要学的

##### Redis部分：

- 使用场景，各个数据结构常用的场景

- 与memocache的区别

  memocache没有丰富的数据结构

  memocache不支持磁盘永久化操作，无论是同步的save还是异步的bgsave，异步操作无需等待

  memocache不支持主从同步，也就无法保证系统的高可用和形成集群

- 字典和跳跃表 ✅

- RDB和AOF持久化机制，RDB就是个快照，AOF好像是命令缓存？

- 集群与分布式 分布式id生成器，其实因为Redis是单线程，但是有可能有进程调度问题

- 事务

- 线程安全问题

### 基本概念整理： 主属性 主键 超键 候选键等

### 三大范式 ✅

##### 第一范式

- 官方：当关系模式R的所有属性都不能在分解为更基本的数据单位时，称R是满足第一范式的，简记为1NF。
- 理解：每一列属性都是不可再分的属性值，确保每一列的原子性。

##### 第二范式

- 官方：满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系；
- 理解：一张表只做一件事情。

##### 第三范式

- 官方：必须先满足第二范式（2NF），且表中的每一列只与主键直接相关而不是间接相关；
- 理解：表中的每一列只能依赖于主键。

这也是数据库设计准则

### 其他链接

##### https://blog.csdn.net/u013630349/article/details/50724244



# 数据库事务

​	数据库管理系统中事务(transaction)的四个特性（分析时根据首字母缩写依次解释）：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。

​	所谓事务，它是一个**操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位**（执行单个逻辑功能的一组指令或操作称为事务）。

```
原子性  事务的原子性是指一个事务要么全部执行，要么不执行。不可能执行一半就停止了，遇到这种情况会回滚rollback
一致性  事务的运行并不改变数据库中数据的一致性，比如a与b之间有某种关系限制，事务改变了a，也势必会改变b
独立性 两个以上的食物不会出现交错执行的状态，因为这样可能导致数据不一致
```



### 事务是什么 ✅

事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行结果必须使数据库从一种一致性的状态变到另一种一致性的状态。

### 事务的特征 ✅

数据库管理系统中事务(transaction)的四个特性（分析时根据首字母缩写依次解释）：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。

​	所谓事务，它是一个**操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位**（执行单个逻辑功能的一组指令或操作称为事务）。

##### **原子性(Atomicity)**

​	原子性是指事务是一个不可再分割的工作单元，事务中的操作要么都发生，要么都不发生。

​	在DBMS中，默认情况下**一条SQL就是一个单独事务**，事务是**自动提交**的。只有显式的使用**start transaction**开启一个事务，才能将一个代码块放在事务中执行。

##### 一致性(**Consistency**)

​	一致性是指在**事务开始之前和事务结束以后**，**数据库的完整性约束没有被破坏**。这是说数据库事务不能破坏**关系数据的完整性**以及**业务逻辑上的一致性**。

​	如A给B转账，不论转账的事务操作是否成功，其两者的存款总额不变（这是业务逻辑的一致性，至于数据库关系约束的完整性就更好理解了）。

##### 隔离性(**Isolation**)

> 所以这里涉及了一个事务的隔离级别的问题

​	**多个事务并发访问时，事务之间是隔离的**，一个事务不应该影响其它事务运行效果。

​	在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。事务查看数据更新时，数据所处的状态要么是另一事务修改它之前的状态，要么是另一事务修改它之后的状态，**事务不会查看到中间状态的数据**。

​	事务最复杂问题都是由事务隔离性引起的。**完全的隔离性是不现实的，完全的隔离性要求数据库同一时间只执行一条事务**，这样会严重影响性能。

##### 持久性(**Durability**)

​	这是最好理解的一个特性：持久性，意味着在事务完成以后，**该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。**（完成的事务是**系统永久的部分**，对系统的影响是永久性的，该修改即使出现致命的系统故障也将一直保持）

额外补充：write ahead logging：SQL Server中使用了WAL（Write-Ahead Logging）技术来保证事务日志的ACID特性，在数据写入到数据库之前，先写入到日志，再将日志记录变更到存储器中。

> 这里就涉及到数据库的主从复制问题了

### 事务并发带来的问题 ✅

##### 脏读

一个事务读取了另一个事务未提交的数据，即一个事务读取了另一个事务正在修改的值，已经改变的值

##### 不可重复读

不可重复读的重点是修改，同时条件下两次读取结果不同，也就是说被读区的数据可以被其他事务修改

##### 幻读

幻读 是事务非独立执行出现的问题，也就是在一个事务读的过程中，幻读的重点在于新增或者删除，同样条件下两次读出来的记录数不一样

幻读和不可重复读，都是读了其他事务已经提交的数据。
幻读和不可重复读都是读取了另一条已经提交的事务（这点与脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是数据记录插入/删除问题，二者关注的问题点不太相同。

### 数据库事务的隔离级别 ✅

代码：

```sql
set session transaction isolation level read uncommitted;
start transaction;
```



##### Serializable (串行化)

ERIALIZABLE（可串行化）：SERIALIZABLE是最高的隔离级别，它通过强制事务串行执行（注意是串行），避免了前面的幻读情况（**实际是读用读锁，写用写锁，读锁和写锁互斥，这么做可以有效的避免幻读、不可重复读、脏读等问题**）由于他大量加上锁，导致大量的请求超时，因此性能会比较底下，再特别需要数据一致性且并发量不需要那么大的时候才可能考虑这个隔离级别。不然ReadWriteLock 读写分离，读锁是共享的，也会出现问题

最高级别，可避免脏读、不可重复读、幻读的发生；//此时并发事务将串行执行，任何事务都不可能同步执行了 无论增删改查

##### Repeatable read (可重复读)

对数据项，加了行锁，可避免脏读、不可重复读的发生；//一旦一个事务对该数据发生读取操作，另一个事务就不可以修改，相当于对该数据项进行加锁

REPEATABLE READ（可重复读）：当隔离级别设置为Repeatable read时，可以避免不可重复读。**在可重复读中，该sql第一次读取到数据后，就将这些数据加锁（悲观锁），其它事务无法修改这些数据，就可以实现可重复读了**。**但这种方法却无法锁住insert的数据，所以当事务A先前读取了数据，或者修改了全部数据，事务B还是可以insert数据提交，这时事务A就会发现莫名其妙多了一条之前没有的数据**，这就是**幻读（针对的是记录总量）**，不能通过行锁来避免。

**MySQL中InnoDB的默认隔离级别就是Repeatable read。**



##### Read committed (读已提交)

可避免脏读的发生；就是 未提交的时候 你看不到别人的数据

READ COMMITTED（提交读）大多数数据库系统（比如Sql Server , Oracle）的默认隔离级别是READ COMMITTED，**这种隔离级别就是一个事务的开始，只能看到已经完成的事务的结果，正在执行的，是无法被其他事务看到的**。这种级别会出现读取旧数据（不可重复读）的现象，**事务A先读取了数据，事务B紧接了更新了数据，并提交了事务，而事务A再次读取该数据时，数据已经发生了改变。**

##### Read uncommitted (读未提交)

READ UNCIMMITTED（未提交读）：**事务中对数据的修改，即使没有提交，其他事务也可以看得到**，这种隔离级别会引起很多问题，如无必要，不要随便使用。

最低级别，任何情况都无法保证，事务中对数据的修改，即使没有提交，其他事务也看得到

隔离级别越高，安全性越高，执行效率也就越低





# 逻辑架构 ✅

**如果让我们来设计一个关系型数据库，我们可能这样设计：**

存储管理

缓存机制

SQL解析（一条SQL就是一个事务，涵盖事务的四大特性）

日志管理

索引管理

锁管理

权限划分 容灾机制 

![](/Users/Haoyu/Documents/typora/%E6%95%B0%E6%8D%AE%E5%BA%93/assets/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1.png)

实际的逻辑结构图如下：

![](/Users/Haoyu/Documents/typora/%E6%95%B0%E6%8D%AE%E5%BA%93/assets/mysql%E9%80%BB%E8%BE%91%E6%9E%B6%E6%9E%84.png)

​	其逻辑结构分为四层，如下：

### Connectors连接层

​	Connectors连接层是一些客户端和连接服务，包含本地的socket通信和大多数基于客户端/服务端工具实现的类似于tcp/ip的通信，主要完成一些类似于连接处理、授权认证及相关的安全方案，在该层上引用了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于ssl的安全链接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。

>  数据库线程池和Java线程池也是一样的，减少线程创建和销毁的CPU开销

### 第二层（服务层）

​	第二层架构主要完成大多数的核心服务功能。如sql接口，并完成缓存的查询。sql的分析和优化 以及部分内置函数的执行。所有跨存储引擎的功能也在这一层实现，如过程，函数等。在该层，服务器会解析查询并创建相应的内部解析树，并对其完成相应的优化如确定查询表的顺序，是否利用索引等。最后生成相应的执行操作。如select语句，服务器还会查询内部的缓存。

**如果缓存空间足够大，这样就解决大量读操作的环境中能够很好的提升系统的性能。**

//读操作真的是很依赖缓存，缓存提高命中率，这样读操作基本是常数级时间复杂度



​	其中各部分功能如下：

- Manager Services & Utilities：系统管理和控制工具
- Connection Pool：

​	管理缓冲用户连接，线程处理等需要缓存的需求。

​	负责监听对 MySQL Server 的各种请求，接收连接请求，转发所有连接请求到线程管理模块。每一个连接上 MySQL Server 的客户端请求都会被分配（或创建）一个连接线程为其单独服务。而连接线程的主要工作就是负责 MySQL Server 与客户端的通信，
​	接受客户端的命令请求，传递 Server 端的结果信息等。线程管理模块则负责管理维护这些连接线程。包括线程的创建，线程的 cache 等。

- SQL interface：接受用户的SQL命令，并且返回用户需要查询的结果。比如select from就是调用SQL Interface
- Parser：

​	SQL命令传递到解析器的时候会被解析器验证和解析。解析器是由Lex和YACC实现的，是一个很长的脚本。

​	在 MySQL中我们习惯将所有 Client 端发送给 Server 端的命令都称为 query ，在 MySQL Server 里面，连接线程接收到客户端的一个 Query 后，会直接将该 query 传递给专门负责将各种 Query 进行分类然后转发给各个对应的处理模块。
​	主要功能：
​	a . 将SQL语句进行语义和语法的分析，分解成数据结构，然后按照不同的操作类型进行分类，然后做出针对性的转发到后续步骤，以后SQL语句的传递和处理就是基于这个结构的。
​	b.  如果在分解构成中遇到错误，那么就说明这个sql语句是不合理的

- Optimizer：

​	SQL语句在查询之前会使用查询优化器对查询进行优化。就是优化客户端请求的 query（sql语句） ，根据客户端请求的 query 语句，和数据库中的一些统计信息，在一系列算法的基础上进行分析，得出一个最优的策略，告诉后面的程序如何取得这个 query 语句的结果。如“选取-投影-联接”策略进行查询。
​	用一个例子就可以理解： select uid,name from user where gender = 1；
​        这个select 查询先根据where 语句进行选取，而不是先将表全部查询出来以后再进行gender过滤；
​        这个select查询先根据uid和name进行属性投影，而不是将属性全部取出以后再进行过滤；
​        将这两个查询条件联接起来生成最终查询结果。

- Caches & Buffers：

​	主要功能是将客户端提交 给MySQL 的 Select 类 query 请求的返回结果集 cache 到内存中，与该 query 的一个 hash 值做一个对应。该 Query 所取数据的基表发生任何数据的变化之后， MySQL 会自动使该 query 的Cache 失效。**（violate 关键字，可见性）**

在读写比例非常高的应用系统中， Query Cache 对性能的提高是非常显著的。当然它对内存的消耗也是非常大的，读操作十分多的应用系统中。

​	如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。这个缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，key缓存，权限缓存等。

### 存储引擎层

存储引擎真正的负责MySQL中数据的存储和提取，服务器通过API与存储引擎进行通信，不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需进行选取。注意：

存储引擎实现对SQL的解析，并且有SQL计划池和数据缓冲区 来实现减少对数据库的请求 

**存储引擎是基于表的，而不是数据库**，我们可以对表进行选用数据引擎

### 数据存储层

主要是将数据存储在运行于裸设备的文件系统之上，并完成于存储引擎的交互。

完成与存储引擎的交互。



# 存储引擎

### MyISAM

​	该引擎是MySQL5.5版本之前使用的默认存储引擎。

- 在索引方面，其使用聚簇索引；
- 在锁方面，其只支持表级锁。

##### 索引上：

MyISAM 使用簇族索引 InnoDB 使用非簇族索引，其实这也和底部实现结构 是B+树有关 不同磁盘块的叶子结点有指针相连，不需要物理上的连续了，簇族索引的结点就是 叶子结点 含有数据，所以

##### 事务上 ：

MyISAM不支持事务，InnoDB支持事务

##### 锁方面：

MyISAM没有行锁，只有表锁，

##### MyISAM适合的场景：

- 全表频繁执行count语句

  ​	InnoDB存储引擎不保存表的具体行数，执行`select count(*) from table`时，需要重新扫描统计表中数据。

  myisam中则使用一个变量记录了表中数据量，执行`select count(*) from table`时，只需要直接读出该变量即可。

- 对数据进行增删改的频率不高，查询非常频繁地情况 因为使用了聚簇索引，在物理上是连续的？

  ​	因为增删改会涉及到锁表操作，虽然插入操作可以通过一些配置支持从表的尾部插入数据，但是依然会产生很多碎片，比较影响性能。

- 适合没有事务的场景

因为MyISAM不支持事务，但是支持表级锁

### InnoDB

​	该引擎是MySQL5.5版本之后使用的默认存储引擎，然后开始支持事务。

- 在索引方面，其使用的是非聚簇索引；

- 在锁方面，其默认使用的是行级锁，也支持行级锁。

  

##### InnoDB适用的场景：

- 数据增删改查都相当频繁；

  ​	因为使用的是行级锁，在增删改时，只有某些行被锁住，而不像MyISAM，每次都是整张表被锁住，这样大大提高了并发性。

- 可靠性要求比较高，要求支持事务



# 数据库索引

### 是什么

##### 简介

​	是帮助MySQL高效获取数据的数据结构（排好序的快速查找数据结构），类似于字典，我们使用字典的时候想要查某个字，实际上是通过字典的偏旁部首查字表或者拼音查字表进行快速定位，这些偏旁部首查字表和拼音查字表就是索引。

##### 以 二叉查找树为例

​	在数据之外，**数据库系统还维护着满足特定查找算法的数据结构**，这些结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高效查找算法。这种数据结构，就是索引。下图就是一种可能的索引方式(二叉查找树)：

![](/Users/Haoyu/Documents/typora/%E6%95%B0%E6%8D%AE%E5%BA%93/assets/%E7%B4%A2%E5%BC%95.png)

​	左边是数据表，一共有两列七条记录，最左边的是数据记录的物理地址（注意逻辑上相邻的记录在磁盘上也并不是一定物理相邻的）。**为了加快Col2的查找，可以维护一个右边所示的二叉查找树，<font color="red">每个节点分别包含索引键值和一个指向对应数据记录物理地址的指针</font>，这样就可以运用二叉查找在O(log2n)的复杂度内获取到相应数据。**

​	物理地址，记录序号，以及数据值，结点中要存索引的键值，和一个指向对应数据记录物理地址的指针

​	其实际图像如下：

![](/Users/Haoyu/Documents/typora/%E6%95%B0%E6%8D%AE%E5%BA%93/assets/%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91.png)

​	但一般来说索引本身也很大，不可能全部存储在内存中，因此索引往往是以索引文件的形式存储在磁盘上。

​	linux开发，所有的东西，都可以看作是文件

​	Java 开发中所说的索引，通常指的都是B 树 (多路搜索树，并不一定是二叉的) 结构组织的索引。

其中聚集索引、次要索引、复合索引、前缀索引、唯一索引**默认使用的都是 B+ 树索引**。

除了 B+ 树索引这种类型外，还有哈希(Hash)索引。

### Mysql索引的种类？✅

##### 聚簇索引和非聚簇索引

聚簇索引的顺序就是数据的物理存储顺序；
索引顺序与数据物理排列顺序无关。

- 因此 一个表最多有一个聚簇索引，聚簇索引的叶结点就是数据节点，而非聚簇索引的叶结点仍然是索引节点，只不过有一个指针指向对应的数据块。
- 聚簇索引确定表中数据的物理顺序，聚簇索引对于那些经常要搜索范围值的列特别有效。使用聚簇索引找到包含第一个值的行后，便可以确保后续索引值的行物理相邻。

非聚簇索引，索引中的项目按索引键值的顺序存储，而表中的信息按另一种顺序存储，所以在索引中要加入指向键值物理地址的指针。

##### 普通索引和唯一索引

索引列的值的唯一性 比如主键就是唯一索引的特殊类型，创建主键的时候，数据库默认会为主键创建一个唯一索引，

普通索引，MYSQL中基本索引类型，没有什么限制，允许在定义索引的列中插入重复值和空值

纯粹为了查询数据更快一点

唯一索引，索引列中的值必须是唯一的，但是允许为空值

主键索引，是一种特殊的唯一索引，不允许有空值，其实创建主键的时候，就会默认创建一口索引，主键约束，就是主键索引

##### 单个索引和复合索引（或者组合索引）

索引列包含的列数

##### mysql复合（组合、联合）索引，最左匹配原则

对于多列索引，必须满足 最左匹配原则即查询条件中

其实就和查字典类似，你首先要匹配最左的字母，a 才能继续往下匹配比如 ao等

 (eg：多列索引col1、col2和col3，则 索引生效的情形包括 col1或col1，col2或col1，col2，col3)。

最左匹配原则对与范围查询会使范围查询字段后的其他字段失效

### 稠密索引与稀疏索引

##### 稠密索引

> ​	对已经拍好序的记录建立索引，可以减少IO次数，进而提升查询效率，索引文件，只保留键和指针，
>
> 这不和B+Tree的实现形式差不多吗，每个结点只保留指向关键码的指针，并不含数据，不和B-Tree一样

​	如果记录是排好序的，我们就可以在记录上建立稠密索引，它是这样**一系列存储块：块中只存放记录的键以及指向记录本身的指针**。稠密索引文件中的索引块保持键的顺序与文件中的排序顺序一致。既然我们假定查找键和指针所占存储空间远小于记录本身，我们就可以认为存储索引文件比存储数据文件所需存储块要少得多。当内存容纳不下数据文件，但能容纳下索引文件时，索引的优势尤为明显。这时，通过使用索引文件，我们每次查询只用一次I/O操作就能找到给定键值的记录。

​	如图所示为一个建立在顺序文件上的稠密索引：

![](../assets/%E7%A8%A0%E5%AF%86%E7%B4%A2%E5%BC%95.png)

​	第一个索引块存放指向前四个记录的指针，第二个索引块存放指向接下来的四个记录的指针，依此类推。

​	稠密索引支持按给定键值查找相应记录的查询。给定一个键值K，我们先在索引块中查找K。当找到K后，我们按照K所对应的指针到数据文件中找到相应的记录。似乎在找到K之前我们需要检索索引文件的每个存储块，或平均一半的存储块。

然而，由于有下面几个因素，基于索引的查找比它看起来更为有效：

1. 索引块数量通常比数据块数量少。

2. 由于键被排序，我们可以使用二分查找法来查找K。若有n个索引块，我们只需查找log2n个块。

   链表可是没有办法二分查找的，所以稠密索引可以用二分查找一定是数组，连续的物理内存。

3. 索引文件可能足够小，以至可以永久地存放在主存缓冲区中。要是这样的话，查找键K时就只涉及主存访问而不需执行I/O操作。

如果索引文件足够小，可以放在主存里，进而减少IO时间，操作系统还是要看一下的，明天吧

数据有没有序不重要，稠密索引必须索引有序，哪怕索引是线性表也没关系

##### 稀疏索引

​	**稀疏索引只为数据文件的每个存储块设一个键-指针对,它比稠密索引节省了更多的存储空间**，但查找给定值的记录需更多的时间。只有当数据文件是按照某个查找键排序时，在该查找键上建立的稀疏索引才能被使用，而稠密索引则可以应用在任何的查找键。如图所示，稀疏索引只为每个存储块设一个键-指针对。键值是每个数据块中第一个记录的对应值。

​	我们假定数据文件已排序，且其键值为连续的10的倍数，直至某个较大的数。我们还继续假定每个存储块可存放四个键-指针对。这样，第一个索引存储块中为前四个数据存储块的第一个键值的索引项，它们分别是10、30、50和70。按照前面假定的键值模式，第二个索引存储块中为第五至第八个数据存储块的第一个键值的索引项，它们分别是90、110、130和150。图中我们还列出第三个索引存储块存放的键值，它们分别是假设的第九至第十二个数据存储块的第一个键值。

![](../assets/稀疏索引.png)

### 优势与劣势 ✅

优势：

- 类似于大学图书馆书目索引，**提高数据检索的效率**，降低数据库的io成本
- 通过索引列对数据进行排序，**降低数据排序的成本**，降低了 CPU 的消耗

劣势：

空间问题 和 有频繁插入的时间效率上 会出现问题。

- 实际上索引也是一张表，该表保存了主键和索引字段，并指向实体表的记录，所以索引列也是要占用空间的。
- 虽然索引大大提高查询速度，但同时也会降低更新表的速度，如对表进行insert, update和delete操作。因为更新表时，MySQL 不仅要保存数据，还要保存一下索引文件每次更新添加了索引列的字段。

### 创建索引的时候要注意什么

- 取离散大的值放在组合索引的前面，左侧，是因为，数据稠密度小 否则树可能会比较深

```
1.非空字段：应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。
你应该用0、一个特殊的值或者一个空串代替空值；

2.取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，
可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高；

3.索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。
这也是为什么用B+树不用B树的原因
```

### 以及什么样的字段适合创建索引？

其实都是经常被使用的字段

- 经常作选择查询的字段
- 经常作表连接的字段
- 经常出现在order by， group by，distinct的字段后面



### 建索引的命令语句

##### 创建

```mysql
CREATE [UNIQUE] INDEX indexName ON tableName(columnName(length));
create index indexname on tableName(columnName(length));
//建立索引

ALTER tableName ADD [UNIQUE] INDEX [indexName] ON (columnName(length));

# 注：添加主键约束、唯一索引也属于添加索引，
# 不过主键约束属于约束，其中一定包含了唯一索引且不允许有 null
# 而唯一索引则允许有 null
```

##### 删除

```mysql
DROP INDEX [indexName] ON tableName;
```

##### 查看

```mysql
SHOW INDEX FROM tableName;
```



### 什么情况下不使用索引	✅

1. 时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度；

2. 空间方面：索引需要占物理空间。
   因此我觉得不使用索引的情况，是数据量并没有想象那么大，创建和维护索引（增删改频繁）相对来说开销较大的时候。

3. 再一个就是，也和我自身的任务有关系，比如我本身的任务就是遍历，检索所有数据，将所有数据读出来，用索引反而要先扫描索引再去扫描所有界面，就有点多余。

### **索引失效**

1. 以“%(表示任意0个或多个字符)”开头的LIKE语句，模糊匹配；

2. OR语句前后没有同时使用索引；

3. 数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型）数据出现隐式转化也会导致索引失效

4. 对带索引的字段做了运算比如

   ```java
   select * from tablename where id-1=1000; //对带索引的id进行了运算
   ```

   

5. 对于多列索引，必须满足 最左匹配原则 (eg：多列索引col1、col2和col3，则 索引生效的情形包括 col1或col1，col2或col1，col2，col3)。按次，先根据第一个关键字来筛选嘛，所以就出现了最左匹配的原则。



### 没有索引的情况下如何快速查询

```

```

### 索引的实现

B+树的性质：
所有的叶子结点中包含了全部关键码的信息，及指向含有这些关键码记录的指针，且叶子结点本身依关键码的大小自小而大的顺序链接；
非终端结点可以看成是索引部分，节点中仅含有其子树根结点中最大（或最小）关键码

一个数据库应用程序应具有以下特征：

1.频繁更新大量记录，因此查询和插入，删除，更新的开销都应尽可能保持低

2.检查根据一个关键码或者多个关键码的组合进行，一个结点需要包含多个关键码

3.使用关键码范围查询（所以要尽量符合引用局部性原理）或者最大，最小值查询，也就是说，希望可以做统计。

### 索引结构的分类

##### 线性索引

最原始的 线性索引，但是线性索引是一个单一的大块，更新时不方便，需要往后挪，因为是非链表构造，不然跳表其实蛮合适的，另外线性索引还有倒排表，也可以看一下。

##### 倒排索引

线性表索引有两个问题，一是线性表索引为了要使用二分搜索，必须是数组形式，所以在关键码增删的时候，数组的数据要移动非常不方便。第二个问题是，相同辅码值的多条记录，每一条记录都在索引中重复那个关键码的值。如果辅码值有重复的关键码值，这样会浪费空间，所以用一种改进的二维数组

每一行对应一个辅码值，一行中包含有这个辅码值的主码。

但是又有问题是，如果采用二维数组，还是有数组长度限制，在一开始初始化的时候就要限定好，如何用链表改写呢？即，一个辅码带有一个指向主码链表的指针，

但是由于链表空间可以不连续，因此一个辅码表各项的 主码链表可能在多个不同磁盘里...

所以 把链表存在数组里，数组每一项是由 主码+指向下一个主码的指针构成，每次取的时候 用next，

不直接随机访问

- B-Tree索引
- Hash 索引
- Full-text 全文索引
- R -Tree 索引
- BitMap索引

##### 二叉查找树索引

在本篇开头的时候介绍过了，二叉查找树作为索引，每个结点存一个键值，并且结点存有指向数据物理地址的指针

但是在面对大量数据的时候，难免会出现树的层次过深的情况，导致频繁IO的出现

另外BST保持平衡也是一件很难的问题，AVL旋转操作可能需要大量的重组操作，每次更新应该只影响一些磁盘块，否则会开销太大

##### B-Tree索引 ✅

该索引结构如下：

![](../assets/B%E6%A0%91.png)

![](../assets/mysqlB+Tree%E7%B4%A2%E5%BC%95%E7%BB%93%E6%9E%84.png)

​	如上图，是一颗b树，浅蓝色的块我们称之为一个磁盘块，可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示），如磁盘块1包含数据项17和35，包含指针P1、P2、P3，P1表示小于17的磁盘块，P2表示在17和35之间的磁盘块，P3表示大于35的磁盘块。

**真实的数据存在于叶子节点**即3、5、9、10、13、15、28、29、36、60、75、79、90、99。

其查找过程如下：

​	如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。

​	**每次磁盘访问都是得到一个磁盘块的信息**

​	100阶的B-Tree可能一个结点就是一个磁盘块，有M-1个指针指向孩子结点，对于同一个结点可能要采用顺序或者二分查找的方式，但是这样相比于BST会大大减少IO的时间。并且十分切合引用局部性原理。

​	真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。

​	以上查找过程也解释了**为什么要使用索引**，一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上，查找过程也增加了io消耗，但相较于没有索引情况下逐个搜索，性能提升巨大。

索引本身也很大，所以，只能一个节点，一个磁盘块一个磁盘块的加载

##### B+Tree索引

- 该索引结构如下：

  ![](../assets/B+%E6%A0%91.png)

![](../assets/B+Tree%20%E7%BB%93%E6%9E%84.png)

- 说明：
  - 非叶子节点仅用来索引，所有的数据都保存在叶子节点中，但是非叶子结点也是数据项，不是b-tree中仅仅指引方向
  - 所有的叶子节点均有一个链指针指向下一个节点（方便做统计），方便做遍历吧，TreeMap和HashMap以及HashSet
  - 非叶子节点的子树指针与关键字个数相同
  - 非叶子节点的子树指针指向关键字值在一定范围内的子树，由图观察规律，写出来还不如直接观察。
- 使用B+树做索引的优点：
  - B+树的磁盘读写代价更低
  - B+树的查询效率（查询时间都是log(n)）更稳定
  - B+树更有利于对数据库的扫描

##### 

##### Hash索引

- 该索引结构图如下：

![](../assets/%E5%93%88%E5%B8%8C%E7%BB%93%E6%9E%84%E7%B4%A2%E5%BC%95.png)

- 优点：查找迅速，时间复杂度为O(1)
- 缺点：
  - 仅仅满足“=”、“IN”，不能使用范围查询；
  - 无法利用索引顺序来避免排序运算；
  - 不能利用部分索引键查询，比如组合查询时，哈希索引方式是通过计算组合键的哈希值来进行查找，而不是单个计算索引键进行查找；
  - 不能避免表扫描，遇到hash相同的情况时，还是需要对entries中的数据进行扫描比较value才能确定；
  - 遇到大量hash相同的情况后性能不一定比 B树 索引效率高

### 数据库索引为什么用b+树

B+树相对于B树来说

1. B+tree的磁盘读写代价更低，因为所有的信息都在叶子节点存着，并且叶子结点之间还以链表的形式互相连接
   B+tree的内部结点 

   叶子结点有并没有指向关键字具体信息的指针(红色部分)，不指向关键字具体信息
   因此其内部结点相对B 树更小。

   如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，内部结点的关键字也可能很大。
   一次性读入内存中的需要查找的关键字也就越多，相对来说IO读写次数也就降低了；

2. B+ Tree的查找效率更加稳定，由于内部结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引，所以，任何关键字的查找必须走一条从根结点到叶子结点的路。
   所有关键字查询的路径长度相同，导致每一个数据的查询效率相当；

3. 遍历的优势 数据库索引采用B+树，而不是B树的主要原因是，对于涉及范围的查找，或者说需要对整个树进行遍历，B+树只需对链表进行遍历，而B树需要中序遍历才行。

```
mysql在没有索引的情况下想达到快速查询，只能采用搜索，分治和排序的策略来
```



- B+Tree： 是InnoDB引擎的索引实现，不同的引擎正如不同版本的虚拟机

- 数据库连接池，如果开发中使用连接池发现可用连接数量不足，可能是什么原因？





# SQL解析与优化

### 一条SQL语句是怎么运行的？

一条SQL语句就是一个事务，SQL语句的解析其实还是要联系到编译原理的知识

首先一条SQL语句来后，先去数据库中的计划缓存看看之前有没有响应的执行计划，如果存在，就直接调用执行已经编译好的计划，节省了计划的编译时间，

如果有已经编译好的计划，下一步就是去数据库的缓冲存储区中找，有没有该计划的执行结果，如果有就直接返回，节省物理查询时间

如果没有找到该计划，则执行对SQL语句的编译

语法分析，看看语法有没有错误，比如合不合sql语句规范啊，此类问题，此时不会核对语意

然后是语义分析，看看语义有没有问题，比如 表 主键存不存在，如果不存在，就是报错并结束事务，返回错误信息给用户

（肯定有一个配置或者查询文件，来帮助引擎来查看到底有什么表和字段，因为不涉及修改，共享读，所以不会发生安全问题）

接下来就是获得锁，获得对象锁，可能是表锁也可能是行锁，比如select * from tablename for update 就是获取表级锁

接下来就是对数据库用户权限的认证，如果数据库用户没有相应的访问权限依旧会报错

解析的最后一步，就是确定最终的执行计划。当语法、语义、权限都验证后，服务器并不会马上给你返回结果，而是会针对你的SQL进行优化，选择不同的查询算法以最高效的形式返回给应用程序。例如在做表联合查询时，服务器会根据开销成本来最终决定采用hash join,merge join ，还是loop join，采用哪一个索引会更高效等等。不过它的自动化优化是有限的，要想写出高效的查询SQL还是要优化自己的SQL查询语句。

确定好执行计划后，服务器就会将执行计划列入计划缓存中

##### 第三部分SQL的执行

服务器对SQL语句解析完成后，服务器才知道这条SQL语句是什么意思

因此操作有两种：

1. 去缓冲数据区中找

2. 如果数据行没有在缓冲数据区中，就会在物理文件中读取，并且存入缓存区域中

   如果涉及到更新，就会先写入再删除

   

##### 最终的执行顺序

执行顺序：

1. FROM 子句返回初始结果集。
2. WHERE 子句排除不满足搜索条件的行。
3. GROUP BY 子句将选定的行收集到 GROUP BY 子句中各个唯一值的组中。
4. 选择列表中指定的聚合函数可以计算各组的汇总值。
5. 此外，HAVING 子句排除不满足搜索条件的行。
6. 计算所有的表达式；
7. 使用order by对结果集进行排序。
8. 查找你要搜索的字段。

先from 再where 然后group by count等聚合函数，最后having去除不满足的行，然后计算，最后order by进行一下排序，按字段返回

##### 补充：缓存与数据库保持一致的策略

先更新缓存，再更新数据库，其实这样是不对的，

先更新数据库 再更新缓存 目前普遍采用的策略，

先更新数据库 再删除缓存 或者再更新缓存是一样的

但是仍旧有一点点可能，就是 写入操作比读操作快，要知道读是共享锁可以并发操作。

（1）缓存刚好失效
（2）请求A查询数据库，得一个旧值
（3）请求B将新值写入数据库
（4）请求B删除缓存
（5）请求A将查到的旧值写入缓存

因为发生概率是在太低，所以就不考虑了，

### SQL优化

1.建索引

2.对某个表进行加锁

```sql
//对某一个字段建立索引
create index indexName on tableName(columnName(length));
drop index indexName on tableName; 
//对某个表 进行加锁
lock tables tablename read; 共享读锁
lock tables tablename write; 排他写锁 表锁
select * from tablename for update; 排他行级锁
select *from tablename where primarykey =??? for update; 
/*这种指明主键的情况 会加行级锁，但是会一行一行加*/
/*数据库事务隔离级别设定*/
set session transaction isolation level read uncommitted;
start transaction;
set session transaction isolation level read uncommitted;



```



### 补充：关于SQL运行慢

其实这是一道综合题

SQL慢是偶尔慢？还是一直很慢？

偶尔慢

比如 SQL语句在SQL计划中没有找到相应的编译语句，需要重新编译，或者在Mysql的数据缓冲区中没有命中相应的执行结果，需要去数据库中取。或者数据缓冲区中的过期了，导致看起来比较慢。

再一个可以考虑一下并发的情况，如果加了锁，抢不到锁没办法啊，一直阻塞等待。

请求过多也没办法啊，数据库连接池就那么几个线程，需要等候

比如 SQL语句 是一直很慢就要找一下问题了

有没有用索引，是否正确的使用索引了，没有使索引失效

再一个就涉及到SQL语句优化的问题了，这个还可以详细说



##### SQL优化

1. 减少模糊查询like的使用次数
2. 尽量先使用where 再用having
3. where先过滤了 再分组

##### 左外连接

##### 右外连接

# MVCC

查询时当前事务的版本号需要大于或等于创建版本号

查询时当前事务的版本号需要小于删除的版本号

事务开始时候的系统版本号，是事务的版本号



MVCC使得大部分支持行锁的事务引擎，不再单纯的使用行锁来进行数据库的并发控制，取而代之的是把数据库的行锁与行的多个版本结合起来，只需要很小的开销,就可以实现非锁定读，从而大大提高数据库系统的并发性能。

- 同时MVCC解决了Repeatable Read的幻读的问题

  Mysql Innodb中行记录的存储格式，除了最基本的行信息外，还会有一些额外的字段，这里主要介绍和MVCC有关的字段：DATA_TRX_ID和DATA_ROLL_PTR。

  **DATA_TRX_ID**：用来标识最近一次对本行记录做修改(insert|update)的事务的标识符, 

  即最后一次修改(insert|update)本行记录的事务id。

  **DATA_ROLL_PTR**：指写入回滚段(rollback segment)的 undo log record (撤销日志记录记录)。

  如果一行记录被更新, 则 undo log record 包含 '重建该行记录被更新之前内容' 所必须的信息。

  

  

![FDEB7C3F-CC03-4D9B-94CC-36CEDB41D4E6](/Users/Haoyu/Documents/Notes-For-Interviews/技术资料/assets/FDEB7C3F-CC03-4D9B-94CC-36CEDB41D4E6.png)



undo log 还没有提交事务的缓存



MVCC是乐观锁的一种实现方式？

总结来说，InnoDB-MVCC是一种系统行为，在REPEATABLE READ隔离级别下，它通过乐观并发控制解决了该隔离级别所不能解决的幻读，但是前提是这些都得依托于事务的封装。尽管如此，它还是无法完全解决一些并发业务场景下的问题，并且过多的事务使用会严重影响系统的性能，这就需要通过用户行为去约束（最开始所提到的乐观锁

**MVCC是一种系统行为，只不过InnoDB实现的MVCC是一种在系统行为上通过非加锁的方式来实现并发控制手段，也是乐观锁的一种表现形式吧**

乐观锁并不是一种具体的技术，乐观锁只是一种并发控制的思想，所有认为“并发事务不算大”而采用非加锁的形式来实现“加锁”效果的控制机制我们都认为它是乐观锁。既然如此，那我们之前提到的乐观锁就不能叫乐观锁了，它只是乐观锁的一种表达方式，是一种在用户行为上通过非加锁的方式来实现并发控制的手段。同样的MVCC更不能称之为乐观锁，只能说InnoDB实现的MVCC是一种在系统行为上通过非加锁的方式来实现并发控制的手段。



### 原理

InnoDB的MVCC，是通过在每行纪录后面保存两个隐藏的列来实现的。这两个列，一个保存了行的创建时间，一个保存了行的过期时间（或删除时间），当然存储的并不是实际的时间值，而是系统版本号。每开始一个新的事务，**系统版本号都会自动递增**。**事务开始时刻的系统版本号会作为事务的版本号**，用来和查询到的每行纪录的版本号进行比较。在REPEATABLE READ隔离级别下，MVCC具体的操作如下：

SELECT
 InnoDB会根据以下两个条件检查每行纪录：

**其实幻读，主要就是插入和删除，update由于加了行级锁，所以可重复读**

- InnoDB只查找版本早于当前事务版本的数据行，即，行的系统版本号小于或等于事务的系统版本号，这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的。

- 行的删除版本，要么未定义，要么大于当前事务版本号。这样可以确保事务读取到的行，在事务开始之前未被删除。

  **是的，如果过期时间小于当前事务版本号的话，说明是在事务之前就被删除了，出现了幻读，已经被删除了。**

   只有符合上述两个条件的纪录，才能作为查询结果返回。

INSERT

- InnoDB为插入的每一行保存当前系统版本号作为行版本号。

DELETE

- InnoDB为删除的每一行保存当前系统版本号作为行删除标识。

UPDATE

- InnoDB为插入一行新纪录，保存当前系统版本号作为行版本号，同时，保存当前系统版本号到原来的行作为行删除标识。

### 优点：

保存这两个额外系统版本号，使大多数读操作都可以不用加锁。这样设计使得读数据操作很简单，性能很好。

### 缺点：

每行纪录都需要额外的存储空间，需要做更多的行检查工作，以及一些额外的维护工作。

### 总结

通过了解实现原理，可以看出MVCC解决了这些问题：

保证了事务周期内数据的一致性。事务A开启后，即使事务B对数据做了修改/新增/删除，不管事务B有没有提交，这些变更对于事务A的SELECT语句都是不可见的，因为这些变更是其它事务发起的，并且是在事务A开启后发生的。也就是说，它解决了不可重复读和幻读的问题。

提高了数据库的并发性能，试想，如果一个数据只有一个版本，那么多个事务对这个数据进行读写是不是需要读写锁来保护? 加锁的话就会造成阻塞，阻塞就会降低并发性能。而在MVCC里，每一个事务都有对应的数据版本，事务A开启后，即使数据被事务B修改，也不影响事务A那个版本的数据，事务A依然可以无阻塞的读取该数据，当然，只是读取不阻塞，写入还是阻塞的，如果事务A也想修改该数据，则必须要等事务B提交释放所有锁后，事务A才可以修改。所以MVCC解决的只是读-写的阻塞问题，写-写依然还是阻塞的。

MVCC 两个版本号，一个是修改创建，一个是删除

在我们要对一行数据进行修改的时候，加行锁，原数据copy到undolog缓存中，

# 数据库锁



### 概述 ✅ 

​	相对其他数据库而言，MySQL的锁机制比较简单，其最显著的特点是不同的存储引擎支持不同的锁机制。比如，MyISAM和MEMORY存储引擎采用的是表级锁（table-level locking）；InnoDB存储引擎既支持行级锁（ row-level locking），也支持表级锁，但默认情况下是采用行级锁。

### 隔离级别 ✅

​	事务的隔离级别有四种，隔离级别高的数据库的可靠性高，但并发量低，而隔离级别低的数据库可靠性低，但并发量高，系统开销小。可靠性由低到高依次为Read uncommitted、Read committed、Repeatable read、Serializable，这四个级别可以逐个解决脏读、不可重复读、幻读这几类问题。

√: 可能出现    ×: 不会出现

|                  | 脏读 | 不可重复读 | 幻读 |
| ---------------- | ---- | ---------- | ---- |
| Read uncommitted | √    | √          | √    |
| Read committed   | ×    | √          | √    |
| Repeatable read  | ×    | ×          | √    |
| Serializable     | ×    | ×          | ×    |

### 锁的分类 ✅

##### 数据库隔离级别的转换

- 不提交读到提交读

  对行加行共享锁，共享读和写 所以会出现不可重复读问题

- 从提交读到可重复读

  对行加共享读锁和排他写锁，当然加了排他锁后，共享读锁也会阻塞掉

- 可重复读如何解决幻读问题

  MVCC 多版本并发控制



从锁的粒度划分：

- 表级锁：开销小，加锁快；

  不会出现死锁(因为MyISAM会一次性获得SQL所需的全部锁)；锁定粒度大，发生锁冲突的概率最高,并发度最低。

- 行级锁：开销大，加锁慢；行级锁开销大，加锁慢。

  会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。

从锁级别上划分：

可以有行级共享锁，行级排他锁

- **读锁(共享锁)**
- **写锁(排它锁)**
- 但是读锁与写锁 是互斥的

从使用方式上划分：

- 乐观锁
- 悲观锁

### 表级锁 ✅

##### 表级读锁、写锁

​	MyISAM 的默认是给表上表锁，而 InnoDB 既支持表锁，也支持行级锁，默认使用的是行级锁。

​	现在先来在MyISAM环境下对表锁进行测试。

​	假设数据库中表`person_info_myisam`中的数据量为2,500,000条，开启两个查询窗口模仿多线程查询情况：

​	窗口一：

```mysql
#该语句单独执行需要几秒钟
select * from person_info_myisam where id between 1 and 2000000;
```

​	窗口二：

```mysql
#该语句单独执行的速度很快
update person_info_myisam set account = account where id = 2000001;
```

​	如果窗口一中sql语句运行的同时同时让窗口二中的sql语句也运行，会发现窗口二中的sql语句运行也卡住，直到窗口一sql语句执行完毕，窗口二的语句才会执行完毕。

##### myisam 的自动加表锁机制 

​	**出现这样情况的原因是myisam使用的是表级锁，在执行 select 查询语句时，myisam会自动为表加上一个表级别的读锁，在执行增删改时，会自动为表加上一个表级别的写锁**。

- 当读锁未被释放时，另外的读操作也可以对表加上读锁，进行读操作，不会受到当前读锁的影响，但若操作想对表加上写锁时，就会自动被阻塞，直到所有的读锁都被释放为止**（共享锁）**；
- 当写锁未被释放时，另外所有想要加锁的操作都会被阻塞，直到当前写锁的释放**（排它锁）**。

##### 显式加锁

​	除了myisam的默认加锁，我们也可以对表进行显式加读锁或写锁。如下所示：

​	窗口一：

```mysql
lock tables person_info_myisam read;	# 加了读锁
lock tables person_info_myisam write;	# 也可以这么用
```

​	窗口二：

```mysql
update person_info_myisam set account = account where id = 2000001;
```

​	在执行完窗口一之后，再执行窗口二的语句时，会发现窗口二的语句一直处于阻塞状态，操作一直不成功。需要释放锁才可以。

```mysql
# 任意窗口，只要下面命令执行，窗口二的语句立马执行成功
unlock tables;
```

### 共享锁与排它锁 ✅

##### 共享锁

​	上述测试中的读锁都是共享锁，即可以多个事务同时进行查询操作，事务之间不会互斥。如下所示：

​	窗口一：

```mysql
#该语句单独执行需要几秒钟
select * from person_info_myisam where id between 1 and 2000000;
```

​	窗口二：

```mysql
#该语句单独执行的速度很快
select * from person_info_myisam where id = 2000001;
```

​	先执行窗口一再执行窗口二，与之前的update操作不同，窗口二立刻执行完毕，并不会因为窗口一中执行的语句而阻塞。

​	总结：上了共享锁之后依然支持上共享锁，不支持上排它锁。如当读锁未被释放时，另外的读操作也可以对表加上读锁，进行读操作，不会受到当前读锁的影响，但若操作想对表加上写锁时，就会自动被阻塞，直到所有的读锁都被释放为止**（共享锁）**；

**但是读、写锁是互斥的。**

##### 排它锁

​	总结：上了排它锁之后就不可以再加入其它的锁。当写锁未被释放时，另外所有想要加锁的操作都会被阻塞，直到当前写锁的释放**（排它锁）**。

​	注：读操作同样可以加上排它锁，如下所示：

```mysql
select * from person_info_myisam for update;
```

##### 共享锁和排它锁的兼容性

|             | 共享锁S | 排它锁X |
| :---------: | :-----: | :-----: |
| **共享锁S** |  兼容   |    ✘    |
| **排它锁X** |    ✘    |    ✘    |

### 乐观锁与悲观锁 ✅

##### 乐观锁

​	乐观锁主要通过版本号来实现，版本号有两种实现方式，分别如下：

- 添加版本号字段

  ​	一般是添加`int(3)`类型的`version`字段。如以下代码所示：

  ```mysql
  CREAT TABLE test(
    id int(2) NOT NULL AUTO_INCREMENT,
    money int(5) NOT NULL,
    version int(3) NOT NULL DEFAULT 0,
    PRIMARY KEY(id)
  ) ENGINE=InnoDB DEFAULT CHARSET=utf8;
  version int(3) Not NULL DEFAULT 0 这样一个数来进行操作。
  ```

  ​	数据每更新一次，就对version字段加一。当提交version信息时，就将数据库中的版本信息与当前version值进行比对，如果一致，则没有发生冲突，直接更新，如果不一致，则发生冲突，可采用自旋操作来尝试更新。

  也可以通过自旋的操作如CAS自旋变量那样，进行尝试更新

  ​	具体操作如下：

  ​	窗口一：

  ```mysql
  # 先获取version
  select version from test where id = 2;
  # 再更新money信息，更新的同时将version版本也更新
  update test set money = 123, version = 0 + 1 where version = 0 and id = 2;
  ```

  ​	窗口二：

  ```mysql
  # 先获取version
  select version from test where id = 2;
  # 再更新money信息，更新的同时将version版本也更新
  update test set money = 456, version = 0 + 1 where version = 0 and id = 2;
  ```

  ​	如上代码所示，当窗口一更新完毕时，窗口二提交update语句就会失败，这时的失败情况就交由开发者来自行处理。 所以这里Version 不一致，进而保证了互斥。

- 添加时间戳

  第二种就是添加时间戳 Timestamp

##### 悲观锁

​	悲观锁在之前已经实现很多，在此不再赘述

之前所说的表锁，行锁，以及根据它们是否可以共享而分的类型，所以锁这块，烂熟于胸应该。

​	

### 乐观锁和悲观锁的具体理解

乐观锁，虽然名字中带“锁”，但是乐观锁并不锁住任何东西，
而是在提交事务时检查这条记录是否被其他事务进行了修改：如果没有，则提交；
否则，进行回滚。
相对于悲观锁，在对数据库进行处理的时候，乐观锁并不会使用数据库提供的锁机制。
如果并发的可能性并不大，那么乐观锁定策略带来的性能消耗是非常小的。
乐观锁采用的实现方式一般是记录数据版本。
乐观锁 其实就是重复写的策略

悲观锁，正如其名，它指的是对数据被外界修改持保守(悲观)态度，
因此，在整个数据处理过程中，将数据处于锁定状态。
悲观锁的实现往往依靠数据库提供的锁机制，也只有数据库层提供的锁机制才能真正保证数据访问的排他性，
否则即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据。
悲观锁的并发控制，实际上是先取锁，再访问的保守策略

### 悲观锁和乐观锁小结





# 数据库连接池

不使用数据库连接池 需要走过 TCP建立三次握手，MySQL认证的三次握手，真正的SQL解析执行，MYSQL连接的关闭，因为MYSQL有一个Connect层，然后就是TCP连接关闭

数据库连接池：第一次访问的时候，需要建立连接，但是之后 均会复用之前连接

##### 连接池的建立

第一、连接池的建立。一般在系统初始化时，连接池会根据系统配置建立，并在池中创建了几个连接对象，以便使用时能从连接池中获取。连接池中的连接不能随意创建和关闭，这样避免了连接随意建立和关闭造成的系统开销。Java中提供了很多容器类可以方便的构建连接池，例如Vector、Stack等。

第二、连接池的管理。连接池管理策略是连接池机制的核心，连接池内连接的分配和释放对系统的性能有很大的影响。其管理策略是：

当客户请求数据库连接时，首先查看连接池中是否有空闲连接，如果存在空闲连接，则将连接分配给客户使用；如果没有空闲连接，则查看当前所开的连接数是否已经达到最大连接数，如果没达到就重新创建一个连接给请求的客户；如果达到就按设定的最大等待时间进行等待，如果超出最大等待时间，则抛出异常给客户。

客户释放数据库连接的时候，判断该连接的引用次数，是否超过了规定值，超过了就销毁，没超过就在连接池中等待 待命

第三、连接池的关闭。当应用程序退出的时候，关闭连接池中所有连接，并且释放相关的资源，和创建过程正好相反

##### 连接池的主要参数

最小连接数，和Java中的corePoolSize差不多

最大连接数 ，没超过这个数就会新建，超过了就会被加入到等待队列中，可以联系一下 java中的blockingQueue

最大空闲时间，KeepAliveTime 大于最小连接数的线程如果等待时间超过最大空闲时间就会被销毁

获取连接超时时间，乐观锁，自旋的获取连接线程

超时重试次数

常用的数据库连接池 比如 Druid 阿里的开源项目，有强大的监控性能



Connect层的，其实还是Java 连接池类似，

# MySQL主从复制

### 复制解决了什么问题

- 实现在不同服务器上的数据分布；
- 实现数据读取的负载均衡；
- 增强了数据的安全性；
- 实现了数据库的高可用和故障切换；
- 实现数据库在线升级。

### MySQL二进制日志

##### mysql日志的分类

​	mysql日志主要分为服务层日志和存储引擎层日志。具体结构如下：

![](../assets/mysql%E6%97%A5%E5%BF%97%E5%88%86%E7%B1%BB.png)

##### mysql二进制日志(log_bin)

1. 简介

   记录了所有对mysql数据库的修改事件，包括增删改查事件和对表结构的修改事件。该日志中只记录已经成功执行的事件，由于回滚、语法错误没能成功执行的事件并不会被成功记录。

2. 二进制日志的格式

   - **基于段（Statement）的二进制格式 binlog_format = STATEMENT**

     该方式下直接记录对数据库操作的SQL语句。MySQL5.7版本之前的默认日志格式。

   - **基于行（ROW）的日志格式 binlog_format = ROW**

     MySQL 5.7 版本之后的默认日志格式。该日志格式记录的是增删改查操作修改的行的记录信息，每修改一行就有一条记录，从而保证Row格式可以避免MySQL复制中出现的主从数据库不一致的问题。

   - **混合日志格式 binlog_format = MIXED**

     该种格式是混合了基于段的二进制格式和基于行的二进制格式。根据SQL语句，由系统选择是使用基于段的记录格式还是基于行的记录格式。大多数SQL语句都是使用段的格式记录，使用了非确定性函数的地方会使用基于行的记录格式。

##### 二进制日志格式对复制的影响

- **若二进制日志是基于Statement格式，则Mysql会使用基于SQL语句的复制( SBR )；**

  主库记录下SQL语句，从库重新执行一遍。

  优点：

  - 日志记录量相对较小，节约磁盘及网络io；
  - 并不强制要求主从数据库表的定义完全相同(如列顺序不一致)；
  - 由于记录的是SQL语句，较容易定位问题的发生。

  缺点：

  - 由于记录的是SQL语句，因此需要额外记录SQL语句执行的上下文环境，但对于一些特定的非确定性函数，如UUID()，还是无法复制，有可能造成MYSQL复制的主从服务器数据不一致问题；
  - 与第一条类似，对于存储过程、触发器和自定义函数的修改也可能造成数据不一致；
  - 相比于基于行的复制，基于 SQL 语句的复制方式在执行时可能需要更多的行锁。

  基于SQL语句的复制方式，可能会获取和释放大量的锁

- **若二进制日志是基于ROW格式，则MYSQL会使用基于行的复制( RBR )；**

  优点：

  - 使MySQL主从复制更加安全，即解决了基于SQL的复制中可能会发生的因为非确定性函数、存储过程而造成的数据不一致问题；
  - 可以减少数据库锁的使用，每次只锁上当前正在更新的那一行即可；
  - 对每一行数据的修改比基于段的复制更加高效；
  - 可以当做数据恢复的一种手段，如果由于误操作修改了数据库中的数据同时又没有备份可以恢复时，我们就可以通过分析二进制日志，对日志中记录的数据处理做反向处理的方式来达到数据恢复的目的

  缺点：

  - 记录日志量较大，MySQL5.6版本之后提供了 `binlog_row_image = [FULL | MINIMAL | NOBLOB]`参数来修改记录日志量的大小，FULL为默认值，即修改行时，将所有的列都记录下来，无论是否被修改；MINIMAL只会记录被修改的列；而NOBLOB与FULL很相似，但不会记录没有被修改的BLOB属性和text属性的列。
  - 要求主从数据库的表结构相同，否则可能会中断复制，即使表中是相同的列，列的顺序也应尽量相同；

- **若二进制日志是基于混合模式，则MYSQL会根据内容在上面两种复制模式中切换。**

### mysql复制工作方式

##### 复制流程

其复制流程如下：

![](../assets/mysql%E5%A4%8D%E5%88%B6%E6%B5%81%E7%A8%8B.png)

其主要流程如下：

1. 主服务器将变更写入二进制日志中；

2. 从服务器读取主服务器的二进制日志并写入到中继日志（relay_log）中；

   要完成该过程，从服务器首先会新建一个IO线程，

   该线程会与主库建立普通的客户端连接，然后会在主库上启动一个特殊的二进制转储线程，称为 bin_log_dump ，从库上的线程通过该二进制转储线程读取主库上发生的变更信息。

   从库不会对事件进行轮询操作，如果从库的更新速度追赶上了主库，它就进入sleep状态，直到主库发送信号通知其又有新的事件产生时，才会被唤醒。

   

   中继日志的格式与二进制日志的格式完全相同。

   

   而根据如何制定从某个位置开始读取主库中二进制日志的方法的不同，又可以分出**基于日志点的复制**和**基于GTID的复制**。

3. 从服务器接受中继日志，并在从服务器上对这些时间进行修改

   从服务器读取中继日志中的事件，并在从服务器上对这些事件进行存放。

   这一步由从服务器上的SQL线程完成。基于SQL段的日志是在从库上重新执行记录的SQL，

   基于行的日志是在从库上直接执行对行的修改。

##### 基于日志点的复制



##### 基于GTID的复制



# MySQL高可用

### 什么是高可用

​	高可用性（HA，High Availability）指的是通过尽量缩短因维护、系统崩溃而造成的停机时间，提高系统的可应用性。

​	所谓的高可用实际上是通过系统的不可用时间长短来衡量的。

​	以下原因均可能降低系统的可用性：

​	软件层面（该情况下Mysql虽然没有崩溃，但对应用来说，已经不能正常的使用数据库。）：

- 严重的主从延迟；

- 主从复制中断；

- 锁引起的大量阻塞；（一个线程占用锁，其他线程阻塞）

  硬件层面(系统直接宕机)：

- 因硬件而导致的系统宕机。

​	**所以我们会使用系统正常可用时间和全年时间百分比来表示高可用程度。**如5个9就表示系统一年中99.999%的时间是可用的，即一年只有5.25分钟的不可用时间。而可用度为99.99%的情况下，系统一年中不可用时间为52.5分钟。

### 如何实现高可用

5-10 什么是高可用架构  2：37

# 分库分表

### 拆分前要做的事

- 第一步：采用分布式缓存redis、memcached等降低对数据库的读操作；
- 第二步：如果缓存使用过后，数据库访问量还是非常大，可以考虑数据库读、写分离原则；
- 第三步：当我们使用读写分离、缓存后，数据库的压力还是很大的时候，这就需要使用到数据库拆分了。数据库拆分原则：就是指通过某种特定的条件，按照某个维度，将我们存放在同一个数据库中的数据分散存放到多个数据库（主机）上面以达到分散单库（主机）负载的效果；

##### 补充：数据库读写分离什么意思？

### 分库分表的几种方式

##### 分库(垂直拆分)

​	对同一集群中的数据库进行拆分。

​	比如，当前集群存储的表有订单数据库、用户数据库、促销数据库等。可以将其进一步进行拆分，订单数据库、用户数据库和促销数据库都单独拆分到新的服务器集群中。这样就将单一节点的读写压力（主要解决写压力，读压力增加从服务器即可）分摊到了三个节点上。

​	如下图所示：

![](../assets/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E5%BA%93.png)

- 优点：相对来说，该种做法实现分库比较简单；
- 缺点：很多情况下，数据库的压力主要来自于特定的某个数据库，如上述中的订单数据库，这样拆分并不能有效缓解压力。

##### 分表(垂直拆分)

​	把一个库中的表分离到不同的数据库中。这样拆分后，每一个数据库承担的只是原来数据库中部分写压力，如下图所示：

![](../assets/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E8%A1%A8.png)

​	这样做法在一段时间之内可以缓解当前遇到的问题，但随着业务的发展，订单表可能又会出现写压力较大的问题。

​	**采用垂直拆分优点：**

- 拆分后业务清晰，拆分规则明确。

- 系统之间整合或扩展容易。

- 数据维护简单。

  **缺点：**

- 部分业务表无法join，只能通过接口方式解决，提高了系统复杂度。

- 受每种业务不同的限制存在单库性能瓶颈，不易数据扩展跟性能提高。

- 事务处理复杂。

##### 分表(水平拆分)

​	垂直拆分后遇到单机瓶颈，可以使用水平拆分。相对于垂直拆分的区别是：垂直拆分是把不同的表拆到不同的数据库中，而水平拆分是把同一个表拆到不同的数据库中。

​	相对于垂直拆分，水平拆分不是将表的数据做分类，而是**按照分区（分片）关键字段的某种规则来分散到多个库（如订单表，以订单的id做分区关键字，进行哈希运算，通过哈希值来确定在哪个表）**之中，每个表中包含一部分数据。简单来说，我们可以将数据的水平切分理解为是按照数据行的切分，就是将表中 的某些行切分到一个数据库，而另外的某些行又切分到其他的数据库中。

​	水平拆分需要注意以下几点：

- 拆分依据关键字段的选择，应尽量保证跨分片查询的发生；

  比如在博客系统中，如果按照博客的id对博客进行拆分就不是很好，因为经常会有查询一个人的所有博客的需求，跨分片查询的性能可能还低于未分片时的性能，如果按照用户id对博客进行分片，则效率会高很多；

- 分区键能尽量使得各个分片中的数据均匀。

- 如何存储无需分片的表

  - 每个分片中存储一份相同的数据，最常见的如字典表，但需要定期维护更新保证数据一致性；
  - 使用额外的节点统一存储，查询效率没有上面高，但数据一致性得到保证，且减少了数据冗余。

- 如何在节点上部署分片

  - 每个分片使用单一数据库，并且数据库名也相同；
  - 将多个分片表存储在一个数据库中，并在表名上加入分片号后缀；//水平拆分
  - 在一个节点中部署多个数据库，每个数据库包含一个分片。

- 如何分配分片中数据，要保证数据尽量均匀，同时也需要保证访问请求量也尽量均匀；

  这需要结合实际场景设计，但通常来说有如下几种手段：

  - 按分区键的hash值取模来分配分片数据；
  - 按分区键的范围来分配分片数据，这种方式常用于分区键为数值类型，但分布难以均匀；
  - 利用分区键和分片的映射表来分配数据。注意使用该种方式映射表会被经常读取，可使用缓存存储，否则可能该映射表成为系统性能的瓶颈。

- 如何生成全局唯一id

  - 使用auto_increment_increment设置自增步长，使用auto_increment_offset参数设置自增起点。保证自增步长与服务器节点数量一致，自增起点分别为服务器节点的序号即可。但该方式只适用于一个节点中只保存一个分区表的情况，无法解决一个节点中保存多个分区表。
  - 在Redis缓存服务器中创建全局id。

在Redis缓存服务器中创建全局id  用setnx 进行全局id的设置 因为是单线程所以线程安全，不用考虑并发问题