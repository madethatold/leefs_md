# 因特网的组成

因特网 = 边缘部分 + 核心部分 = 资源子网 + 通信子网

结构如下：

![](../assets/%E5%9B%A0%E7%89%B9%E7%BD%91%E7%9A%84%E7%BB%84%E6%88%901.png)

##### 核心部分：让计算机网络能够通讯的部分

##### 边缘部分：接到因特网上的计算机

![](../assets/%E5%9B%A0%E7%89%B9%E7%BD%91%E7%9A%84%E7%BB%84%E6%88%902.png)

##### 因特网的边缘部分

边缘部分，计算机的组成的拓扑结构一般我们了解

CS的方式和P2P的方式



主机之间的通讯方式：客户端/服务器方式(Client/Server，CS)，对等方式(Peer-to-Peer，p2p)

- 客户端/服务器方式：客户向服务器请求服务，服务器为客户端提供服务，**这样访问的人越多，网速越慢**。

![](../assets/%E5%9B%A0%E7%89%B9%E7%BD%91%E7%9A%84%E7%BB%84%E6%88%903.png)

- 对等方式（p2p）：每个客户端都可以成为服务器。如常见的p2p下载，第一台客户端向服务器请求资源下载后，自身运行p2p程序，也变成了服务器，其它用户再请求资源下载时，就可以直接从该客户端进行下载。这样情况下，**下载人越多，下载速度越快。**

![](../assets/%E5%9B%A0%E7%89%B9%E7%BD%91%E7%9A%84%E7%BB%84%E6%88%904.png)

##### 因特网的核心部分

核心部分我们主要了解三种交换方式的不同

数据交换的方式：电路交换、报文交换和分组交换。

- 电路交换（Circuit Switching）：原理如下，典型的应用就是打电话，两台电话在需要通信的时候就将它们连起来，不需要通信的时候就将它们的连接释放。

  电路交换面向连接，连接过程为：建立连接（申请占用通信资源） -> 通话（持续占用通信资源） -> 释放连接（释放通信资源）

  不同交换机之间也可以通过中继线连接，交换机与用户之间通过用户线连接，这样就实现了跨交换机长途连接，如从安徽给北京打电话，就需要跨越交换机。

  **电路交换适用于数据量很大的实时性传输**。核心路由之间可能用到电路交换。

![](../assets/%E5%9B%A0%E7%89%B9%E7%BD%91%E7%9A%84%E7%BB%84%E6%88%905.png)

- 分组交换（Packet Switching）：原理即发送端将待发送的信息（报文）进行分段，每一段都额外加上首部，其中包含的数据有地址信息、序号信息等。分段发送到接收端，接收端收到分段信息后，根据首部信息将不同的段落进行组装，最终获取完整的信息。

  **分组交换适用于计算机网络**。

  下图即为分组转发示意图，其中ABCDE为路由器节点，路由器节点具有**存储转发**的功能。

![](../assets/%E5%9B%A0%E7%89%B9%E7%BD%91%E7%9A%84%E7%BB%84%E6%88%906.png)

- 报文交换（Message Switching）：报文交换与分组交换类似，都需要写地址，但报文交换不需要将报文进行分组，而是直接发送。报文交换的时延比较长。

三种发送方式的比较：纵轴为时间轴

![](../assets/%E5%9B%A0%E7%89%B9%E7%BD%91%E7%9A%84%E7%BB%84%E6%88%907.png)

解析：

1. 电路交换方式下是先在ABCD设备间建立连接，之后发送数据，可以看到数据在不同设备之间的传输十分连续快速，最后释放连接。

2. 报文交换方式下，报文从A设备逐个发送到BCD设备，耗时长。

   //要实现有序？所以分组发是一个像串行化的感觉

3. 分组交换方式下，将报文分组，并行传输，十分快速。

# 计算机网络面试问题集锦

## OSI参考模型与TCP/IP参考模型

![img](https://s1.ax1x.com/2018/02/22/9UJf5F.png)

OSI参考模型注重“通讯协议必要的功能是什么”

TCP/IP强调“在计算机上实现协议应该开发哪些程序“

## 应用层

### https

##### 简介

​	https全称为Hyper Text Transfer Protocol Secure，其协议依赖结构与与http协议依赖结构对比如下：

![](../assets/http%E4%B8%8Ehttps.png)

- SSL	

  SSL（Security Sockets layer）安全套接层，是为网络通信提供安全服务及数据完整性的一种协议。其是操作系统对外提供的API，SSL3.0之后更名为TLS(Transport Layer Security，安全传输层协议)。其主要通过身份认证和数据加密来保证网络通信的安全和数据的完整性。

- 加密的方式

  - 对称加密：AES加密和解密都使用同一个密钥，该算法优点是简单、效率高。
  - 非对称加密：如RSA加密，加密使用的密钥（**公钥**）和解密使用的密钥（**私钥**）是不同的。公钥和算法都是公开的，私钥是保密的。区块链技术采用的就是非对称加密。非对称加密性能较低，加密数据长度有限，但是安全性超强。
  - 哈希算法：将任意长度的信息转换为固定长度的值，算法不可逆，如md5加密算法。
  - 数字签名：证明某个消息或者文件是某人发出/认同的，其就是在信息后面加上一段内容，该签内容是经过哈希函数后的值，可以证明该信息没有被修改过。
  
  数字签名，犹如版本号的存在

##### **HTTPS 数据传输流程**

- 浏览器将支持的加密算法信息发送给服务器；
- 服务器选择一套浏览器支持的加密算法，以证书的形式回发浏览器。证书包含了证书发布的CA机构、证书的有效期、公钥等；
- 浏览器验证证书合法性，并结合证书公钥加密信息发送给浏览器；
- 服务器使用私钥解密信息，验证哈希，加密响应消息回发给浏览器；
- 浏览器解密响应消息，并对消息进行验真，之后进行加密交互数据。

注意：公钥是由服务器发送给浏览器！

##### http与https区别

- HTTPS需要到CA申请证书，http不需要；
- HTTPS采用TLS安全传输层协议，是密文传输数据，而HTTP是明文传输数据；
- 连接方式不同，默认使用端口不一样，https 默认使用443端口，HTTP 默认使用80端口；
- HTTPS=HTTP+加密+认证+完整性保护，较http安全。



### http和https的区别 ✅

什么是https，说说https的工作原理
Http协议和https都是应用层协议，运行在TCP之上，明文传输，客户端与服务器端都无法验证对方的身份；Https是身披SSL(Secure Socket Layer)外壳的Http，运行于SSL上，SSL运行于TCP之上，是添加了加密和认证机制的HTTP。二者之间存在如下不同：
1.端口不同：Http与Http使用不同的连接方式，用的端口也不一样，前者是80，后者是443；
2.资源消耗：和HTTP通信相比，Https通信会由于加减密处理消耗更多的CPU和内存资源；
3.开销：Https通信需要证书，而证书一般需要向认证机构购买； 
Https的加密机制是一种共享密钥加密和公开密钥加密并用的混合加密机制。

##### 补充：为什么TCP链接需要三次握手，两次不可以么，为什么？✅

不可以，考虑一下网络延迟导致的SYN包问题，服务端收到了一个，但是它可能以为这是一个现在的链接请求,于是发送ACK回去。
这时候两次握手和三次握手的区别就出现了。
如果是两次握手，那么ACK发回去后，服务器端就认为是链接已经建立，双方可以通信了，但是实际上是一个延迟包，客户端根本没有数据要传给服务端

##### 补充：客户端不断进行请求链接会怎么样，DDos攻击？✅

就是client一直发请求 但是不确认，缺最后一次握手
DDos预防（没有彻底根治办法，除非不使用Tcp）
  限制同时打开的SYN半链接的数目
  缩短SYN半链接的Time out时间
  关闭不必要的服务，别留那么多服务口？

##### 补充：对称加密与非对称加密✅

对称密钥加密是指加密和解密使用同一个密钥的方式，这种方式存在的最大问题就是密钥发送问题，即如何安全地将密钥发给对方；

而非对称加密是指使用一对非对称密钥，即公钥和私钥，公钥可以随意发布，但私钥只有自己知道。发送密文的一方使用对方的公钥进行加密处理，对方接收到加密信息后，使用自己的私钥进行解密，因此需要知道对方的公钥。
传输用对称加密，因为很快，但是对密钥进行二次加密 采用非对称加密的方式

关于速度问题？
我觉得是算法问题
AES比RSA快1500倍左右，RSA生成一个密钥都要0.6秒左右，更别说完整运行整个加密算法，对报文内容进行加密了。

### **谈谈你对http协议的理解✅**

Http协议 是web的应用层协议，之所以称为应用层协议，是因为它无需关心数据是通过什么方式到达对端的，只需要协商好使用的数据格式，保证一方可以解析出另一方的意图即可。
Http协议 定义了Web客户机是如何向Web服务器发送
Http协议是无状态的
剩下的话，还可以从URL格式，Http请求报文段，方法名，Http响应报文段来理解Http协议

### http报文结构 

##### 请求报文

HTTP报文有两种：请求报文和响应报文
HTTP请求报文的第一行叫做请求行（Request Line）请求行有3个字段
方法字段：GET，POST，PUT，DELETE
URL字段：schema://host[:port]/path/.../[?query-string][#anchor] 锚 内部路由用得到
HTTP协议版本字段 HTTP/1.1之类的

其后继行叫做首部行（HeaderLine）

如首部行 Connection: close浏览器告诉服务器不希望麻烦地使用持久连接
User-agent 首部行用来定义用户代理 如浏览器
Content-Type：application/x-www-form-urlencoded 指定内容的编码格式

之后就是报文内容



##### 响应报文

HTTP响应报文，Response消息的结构也由三部分组成，初始状态行，六个首部行，实体主题
状态/请求行  然后就是首部行 然后就是实体主体 
状态行： 

**由协议版本，状态码和相应状态信息组成，响应报文**

首部行：
Connection Date 
Server 
Last-Modified 
Content-Length 
Content-Type 
六个首部行
HTTP报文的结构（一个报文通过套接字下放到TCP连接，对于非持久连接来说，每来一个报文就会开启一个TCP连接，就需要分配相应的缓存和计算资源，就会造成比较大的负载）

HTTP头部（HTTP Request Header 和 HTTP Response Header其实就是首部行）

### Get与POST的区别✅

##### 功能

##### REST服务上说

##### 请求参数上讲

##### 安全性而言

##### 请求长度而言

1. 从功能上讲，GET一般用来从服务器上获取资源，POST一般用来更新服务器上的资源；

2. 从REST服务角度上说，GET是幂等的，即读取同一个资源，总是得到相同的数据，而POST不是幂等的，因为每次请求对资源的改变并不是相同的；进一步地，GET不会改变服务器上的资源，而POST会对服务器资源进行改变；

   在正确实现的条件下，GET，HEAD，PUT 和 DELETE 等方法都是幂等的，而 POST 方法不是。

   GET /pageX HTTP/1.1 是幂等的，连续调用多次，客户端接收到的结果都是一样的：

3. 从请求参数形式上看，GET请求的数据会附在URL之后，即将请求数据放置在HTTP报文的 请求头 中，以?分割URL和传输数据，参数之间以&相连。特别地，如果数据是英文字母/数字，原样发送；否则，会将其编码为 application/x-www-form-urlencoded MIME 字符串(如果是空格，转换为+，如果是中文/其他字符，则直接把字符串用BASE64加密，得出如：%E4%BD%A0%E5%A5%BD，其中％XX中的XX为该符号以16进制表示的ASCII)；而POST请求会把提交的数据则放置在是HTTP请求报文的 请求体 中。

4. 就安全性而言，POST的安全性要比GET的安全性高，因为GET请求提交的数据将明文出现在URL上，而且POST请求参数则被包装到请求体中，相对更安全。

5. 从请求的大小看，GET请求的长度受限于浏览器或服务器对URL长度的限制，允许发送的数据量比较小，而POST请求则是没有大小限制的。

### 说说有哪些请求提交方式？✅

Get,Post,Head,Options,Put,Delete，但是其实还有更多

只有Post是不幂等的，即发送不会收到回复，而其他，每次都会收到回复，GET每次收到的回复还应该是相同的

Head就像GET 只不过服务端接收到HEAD请求后只返回响应头，而不会发送响应内容。
当我们只需要查看某个页面的状态的时候，使用Head是非常高效的，因为在传输过程中省去了页面内容

### 状态码

​	当浏览者访问一个网页时，浏览者的浏览器会向网页所在服务器发出请求。当浏览器接收并显示网页前，此网页所在的服务器会返回一个包含HTTP状态码的信息头（server header）用以响应浏览器的请求。

​	下面是常见的HTTP状态码：

- 200 - 请求成功
- 301 - 资源（网页等）被永久转移到其它URL
- 404 - 请求的资源（网页等）不存在
- 500 - 内部服务器错误

http 的状态码分类如下：

| 分类 | 分类描述                                       |
| ---- | ---------------------------------------------- |
| 1**  | 信息，服务器收到请求，需要请求者继续执行操作   |
| 2**  | 成功，操作被成功接收并处理                     |
| 3**  | 重定向，需要进一步的操作以完成请求             |
| 4**  | 客户端错误，请求包含语法错误或无法完成请求     |
| 5**  | 服务器错误，服务器在处理请求的过程中发生了错误 |

HTTP状态码列表:

常见状态码：

200

201

202

| 状态码   |         状态码英文名称          | 中文描述                                                     |
| :------- | :-----------------------------: | ------------------------------------------------------------ |
| 100      |            Continue             | 继续。[客户端](http://www.dreamdu.com/webbuild/client_vs_server/)应继续其请求 |
| 101      |       Switching Protocols       | 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议 |
|          |                                 |                                                              |
| 200✅     |               OK                | 请求成功。一般用于GET与POST请求                              |
| 201✅     |             Created             | 已创建。成功请求并创建了新的资源                             |
| 202✅     |            Accepted             | 已接受。已经接受请求，但未处理完成                           |
| 203✅     |  Non-Authoritative Information  | 非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本 |
| 204✅     |           No Content            | 无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档 |
| 205      |          Reset Content          | 重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域 |
| 206      |         Partial Content         | 部分内容。服务器成功处理了部分GET请求                        |
|          |                                 |                                                              |
| 300✅     |        Multiple Choices         | 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择 |
| 301✅     |        Moved Permanently        | 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替 |
| 302✅     |              Found              | 临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI |
| 303✅     |            See Other            | 查看其它地址。与301类似。使用GET和POST请求查看               |
| 304      |          Not Modified           | 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源 |
| 305      |            Use Proxy            | 使用代理。所请求的资源必须通过代理访问                       |
| 306      |             Unused              | 已经被废弃的HTTP状态码                                       |
| 307      |       Temporary Redirect        | 临时重定向。与302类似。使用GET请求重定向                     |
|          |                                 |                                                              |
| **400**  |           Bad Request           | 客户端请求的语法错误，服务器无法理解                         |
| 401      |          Unauthorized           | 请求要求用户的身份认证                                       |
| 402✅     |        Payment Required         | 保留，将来使用                                               |
| 403      |            Forbidden            | 服务器理解请求客户端的请求，但是拒绝执行此请求               |
| **404✅** |            Not Found            | 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置"您所请求的资源无法找到"的个性页面 |
| 405✅     |       Method Not Allowed        | 客户端请求中的方法被禁止                                     |
| 406      |         Not Acceptable          | 服务器无法根据客户端请求的内容特性完成请求                   |
| 407      |  Proxy Authentication Required  | 请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权 |
| 408      |        Request Time-out         | 服务器等待客户端发送的请求时间过长，超时                     |
| 409      |            Conflict             | 服务器完成客户端的PUT请求是可能返回此代码，服务器处理请求时发生了冲突 |
| 410      |              Gone               | 客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置 |
| 411      |         Length Required         | 服务器无法处理客户端发送的不带Content-Length的请求信息       |
| 412      |       Precondition Failed       | 客户端请求信息的先决条件错误                                 |
| 413      |    Request Entity Too Large     | 由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息 |
| 414      |      Request-URI Too Large      | 请求的URI过长（URI通常为网址），服务器无法处理               |
| 415      |     Unsupported Media Type      | 服务器无法处理请求附带的媒体格式                             |
| 416      | Requested range not satisfiable | 客户端请求的范围无效                                         |
| 417      |       Expectation Failed        | 服务器无法满足Expect的请求头信息                             |
|          |                                 |                                                              |
| 500✅     |      Internal Server Error      | 服务器内部错误，无法完成请求                                 |
| 501✅     |         Not Implemented         | 服务器不支持请求的功能，无法完成请求                         |
| 502✅     |           Bad Gateway           | 作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应 |
| 503✅     |       Service Unavailable       | 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中 |
| 504      |        Gateway Time-out         | 充当网关或代理的服务器，未及时从远端服务器获取请求           |
| 505✅     |   HTTP Version not supported    | 服务器不支持请求的HTTP协议的版本，无法完成处理               |

<hr>
200 OK Get post请求成功后就会返回这个

201 create Success

202 Accept Success 处理未完成

203 Non-Authoritative Information 服务器返回的信息meta未经授权

204 No Content 无内容 请求成功，但是服务器并未返回内容



300 多重选择，多个匹配位

301 Moved permanently 永久转移

302 Found 临时移动 URI ，但是资源仍和原来一样，使用相同的URI，这个302有可能是因为cookie导致的

303 See other 看看其他地方有没有

304 Not Modified 未修改

305 代理



400 Bad Request 请求语法错误 服务端无法理解

401 Not authentication 未经验证 要求用户的身份验证

402 Payment 保存请求 将来待用

403 Forbidden 用户的相关请求被禁止，服务端理解 但是拒绝执行

404 Not Found 用户

405 Method Not Allowed 客户端请求中的方法被禁止

406 Not Acceptable 服务器无法根据客户端请求的内容特性完成请求

408 Request Timed-out 相应超时



500 Internal Server Error 服务端内部错误 未能及时返回响应

501 Not Implemented 服务端不支持该请求，该请求的方法

502 Bad GateWay 网关错误，访问被拦截，尝试执行请求，返回无效响应

503 Service Unavailable 当前服务不可用 延时长度 可以放在retry-after响应头中

504 GateWay time-out 充当网关或者代理的服务器未能及时从远程服务器获得响应

505  Http Version Not Support

### http 缓存机制

http缓存机制，浏览器会对请求的静态文件进行缓存，但是为什么被缓存，缓存是怎样生效的不是太清楚

response报文中，有cookie这一常用的客户端缓存，但是其实浏览器，还有一个缓存数据库

这个缓存数据库有两种缓存方式，一种是强制缓存，一种是对比缓存，对比缓存每次都要与客户端进行沟通验证

1. 前言

   ​	Http 缓存机制作为 web 性能优化的重要手段，对于从事 Web 开发的同学们来说，应该是知识体系库中的一个基础环节，同时对于有志成为前端架构师的同学来说是必备的知识技能。
   ​	但是对于很多前端同学来说，仅仅只是知道浏览器会对请求的静态文件进行缓存，但是为什么被缓存，缓存是怎样生效的，却并不是很清楚。

2. HTTP报文

   HTTP报文就是浏览器和服务器间通信时发送及响应的数据块。
   浏览器向服务器请求数据，发送请求(request)报文；服务器向浏览器返回数据，返回响应(response)报文。
   报文信息主要分为两部分

   - 包含属性的首部(header)--**附加信息（cookie，缓存信息等）与缓存相关的规则信息，均包含在header中**；
   - 包含数据的主体部分(body)--HTTP请求真正想要传输的部分。

3. 缓存规则解析

   ​	为方便大家理解，我们认为浏览器存在一个缓存数据库,用于存储缓存信息。
   ​	在客户端第一次请求数据时，此时缓存数据库中没有对应的缓存数据，需要请求服务器，服务器返回后，将数据存储至缓存数据库中。

   ![](../assets/http%20%E7%BC%93%E5%AD%98%E2%80%94%E2%80%94%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%AF%B7%E6%B1%82%E6%95%B0%E6%8D%AE.png)

   ​	HTTP缓存有多种规则，根据是否需要重新向服务器发起请求来分类，我将其分为两大类(强制缓存，对比缓存)
   在详细介绍这两种规则之前，先通过时序图的方式，让大家对这两种规则有个简单了解。

   ​	已存在缓存数据时，仅基于强制缓存，请求数据的流程如下：

   ![](../assets/http%20%E5%BC%BA%E5%88%B6%E7%BC%93%E5%AD%98.png)

   ​	已存在缓存数据时，仅基于对比缓存，请求数据的流程如下：

   ![](../assets/http%20%E5%AF%B9%E6%AF%94%E7%BC%93%E5%AD%98.png)

   ​	对缓存机制不太了解的同学可能会问，基于对比缓存的流程下，不管是否使用缓存，都需要向服务器发送请求，那么还用缓存干什么？这个问题，我们暂且放下，后文在详细介绍每种缓存规则的时候，会带给大家答案。

   ​	我们可以看到两类缓存规则的不同，强制缓存如果生效，不需要再和服务器发生交互，而对比缓存不管是否生效，都需要与服务端发生交互。
   ​	**两类缓存规则可以同时存在，强制缓存优先级高于对比缓存，也就是说，当执行强制缓存的规则时，如果缓存生效，直接使用缓存，不再执行对比缓存规则**。

4. **强制缓存**

   ​	从上文我们得知，强制缓存，在缓存数据未失效的情况下，可以直接使用缓存数据，那么浏览器是如何判断缓存数据是否失效呢？
   ​	我们知道，在没有缓存数据的时候，浏览器向服务器请求数据时，服务器会将数据和缓存规则一并返回，缓存规则信息包含在响应header中。

   ​	**对于强制缓存来说，响应header中会有两个字段来标明失效规则**（Expires/Cache-Control）
   ​	使用chrome的开发者工具，可以很明显的看到对于强制缓存生效时，网络请求的情况：

   ![](../assets/http%20%E5%BC%BA%E5%88%B6%E7%BC%93%E5%AD%98%E5%AE%9E%E4%BE%8B.png)

   强制缓存中，有以下几个请求头需要注意：

   - **Expires**：Expires的值为服务端返回的到期时间，即下一次请求时，请求时间小于服务端返回的到期时间，直接使用缓存数据。

     不过Expires 是HTTP 1.0的东西，现在默认浏览器均默认使用HTTP 1.1，所以它的作用基本忽略。另一个问题是，到期时间是由服务端生成的，但是客户端时间可能跟服务端时间有误差，这就会导致缓存命中的误差。所以HTTP 1.1 的版本，使用Cache-Control替代。

   - **Cache-Control**：Cache-Control 是最重要的规则。常见的取值有private、public、no-cache、max-age，no-store，默认为private：

     - private:             客户端可以缓存；
     - public:              客户端和代理服务器都可缓存（前端的同学，可以认为public和private是一样的）
     - max-age=xxx:   缓存的内容将在 xxx 秒后失效
     - no-cache:          需要使用对比缓存来验证缓存数据（后面介绍）
     - no-store:           所有内容都不会缓存，强制缓存，对比缓存都不会触发

     ​	如下图所示：

     ​	![](../assets/http%20%E5%BC%BA%E5%88%B6%E7%BC%93%E5%AD%98%E5%AE%9E%E4%BE%8B2.png)

     图中Cache-Control仅指定了max-age，所以默认为private，缓存时间为31536000秒（365天）
     也就是说，在365天内再次请求这条数据，都会直接获取缓存数据库中的数据，直接使用。

5. **对比缓存**

   ​	**对比缓存，顾名思义，需要进行比较判断是否可以使用缓存**。浏览器第一次请求数据时，服务器会将缓存标识与数据一起返回给客户端，客户端将二者备份至缓存数据库中。再次请求数据时，客户端将备份的缓存标识发送给服务器，服务器根据缓存标识进行判断，判断成功后，返回304状态码，通知客户端比较成功，可以使用缓存数据。

   ​	对比缓存的请求实例如下：

   - 第一次访问：

     ![](../assets/http%20%E5%AF%B9%E6%AF%94%E7%BC%93%E5%AD%981.png)

   - 第二次访问：

     ![](../assets/http%20%E5%AF%B9%E6%AF%94%E7%BC%93%E5%AD%982.png)

   ​	通过两图的对比，我们可以很清楚的发现，在对比缓存生效时，状态码为304，并且报文大小和请求时间大大减少。原因是，**服务端在进行标识比较后，只返回header部分，通过状态码通知客户端使用缓存，不再需要将报文主体部分返回给客户端**。

   ​	对于对比缓存来说，缓存标识的传递是我们着重需要理解的，它在请求header和响应header间进行传递，
   一共分为两种标识传递，接下来，我们分开介绍。

   - **Last-Modified**：服务器在响应请求时，告诉浏览器资源的最后修改时间。

     ![](../assets/http%20%E5%AF%B9%E6%AF%94%E7%BC%93%E5%AD%983.png)

   - **If-Modified-Since**：**再次请求服务器时，通过此字段通知服务器上次请求时，服务器返回的资源最后修改时间**。服务器收到请求后发现有头If-Modified-Since 则与被请求资源的最后修改时间进行比对。若资源的最后修改时间大于If-Modified-Since，说明资源又被改动过，则响应整片资源内容，返回状态码200；若资源的最后修改时间小于或等于If-Modified-Since，说明资源无新修改，则响应HTTP 304，告知浏览器继续使用所保存的cache。

     ![](../assets/http%20%E5%AF%B9%E6%AF%94%E7%BC%93%E5%AD%984.png)

   - **Etag**：服务器响应请求时，告诉浏览器当前资源在服务器的唯一标识（生成规则由服务器决定），优先级高于Last-Modified。

     ![](../assets/http%20%E5%AF%B9%E6%AF%94%E7%BC%93%E5%AD%98etag.png)

   - **If-None-Match**：再次请求服务器时，通过此字段通知服务器客户段缓存数据的唯一标识。服务器收到请求后发现有头If-None-Match 则与被请求资源的唯一标识进行比对，不同，说明资源又被改动过，则响应整片资源内容，返回状态码200；相同，说明资源无新修改，则响应HTTP 304，告知浏览器继续使用所保存的cache。

     ![](../assets/http%20%E5%AF%B9%E6%AF%94%E7%BC%93%E5%AD%98if%20noneMatch.png)

6. 总结

   - **对于强制缓存，服务器通知浏览器一个缓存时间，在缓存时间内，下次请求，直接用缓存，不在时间内，执行比较缓存策略；**
   - **对于比较缓存，将缓存信息中的Etag和Last-Modified通过请求发送给服务器，由服务器校验，返回304状态码时，浏览器直接使用缓存。**

   总体流程如下：

   - 浏览器第一次请求：

     ![](../assets/http%E7%BC%93%E5%AD%98%E6%B5%8F%E8%A7%88%E5%99%A8%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%AF%B7%E6%B1%82.png)

   - 浏览器第二次请求：

     ![](../assets/http 缓存浏览器第二次请求.png)

### http中的状态码都代表什么状态 ✅

其实就是http请求中的状态码，状态码分成五大类，范围从100到599

- 100-199 代表信息性状态码 使用得不多
  200-299代表成功状态码 比如200
  300-399代表重定向状态码 这些状态码告知客户端要么使用替代的位置访问想要的资源，要么告知服务器可以返回什么来代替资源内容
  400-499代表客户端错误状态码
  500-599代表服务器错误状态

- 200 OK: 请求成功，信息包含在返回的响应报文中

- 301 Moved Permanently: 请求对象已经被永久转移了
  302 303 暂时转移 See other: 对应当前请求对响应可以在另一个URL上被找到，而且客户端应当采用Get的方式访问那个资源 

- 400 Bad Request: 用于告知客户端它发送了一个错误的请求，指示该请求不能被服务器理解。
  403 Forbidden: 用于说明请求被服务器拒绝了，拒绝理由可以用实体部分返回描述
  404 Not Found:被请求的文档不在服务器上 路径名不对，或者REST接口请求不合规范
  405 Method Not Allowed 发起的请求中带有所请求的URL不支持的方法时

- 500 Internal Server Error: 服务器遇到一个妨碍它为请求提供服务的错误时，使用此状态码
  502 Bad Gateway:
  503 Server Unavailable 服务器当前不能处理客户端的请求，一段时间后可恢复正常

### 浏览器请求全部流程

当用户在浏览器上输入一段网址后，主要经历了以下过程

1. 首先是dns解析，通过域名找到ip地址
2. 然后向对应ip地址和端口发送连接请求，服务器接受请求（三次握手）
   三次握手完毕后，
3. 浏览器发送Http请求报文段
   （当然考虑到网络层，是网络层根据TCP协议把包都收完后一起向上提交的）
4. 服务器解析Http请求，生成响应报文段，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器。
5. 浏览器解析Http响应，解析并渲染视图，若遇到对js文件，css文件以及图片等静态资源的引用，则重复上述步骤并向服务器请求这些资源，将资源信息显示在屏幕上
6. 保持连接或者断开连接，取决于是否开启Keep-alive//断开连接就有4次挥手的过程



### http1.0与http1.1

##### 缓存处理 

1.0主要通过header的首部字段来做为缓存标准，

1.1则引入了更多的缓存头来控制缓存策略

##### 带宽优化及网络连接的使用

http1.0 存在一些浪费带宽的现象，并且不支持断点续传

1.1则引入了range头域，它允许只请求，资源的某个部分，即返回码206

在请求头中引入了range头域，返回码206 说明可以请求资源的某个部分

##### 错误通知管理

新增了24个错误状态响应码

新增了新的24个错误状态响应码

##### Host头处理

在Http1.0 ip和机器是1V1的 这就对一台物机器上的多个虚拟机很不优化

在Http1.1 就引入了主机名，请求消息和响应消息都应支持Host头域

http1.1引入了主机名称，请求消息和响应消息都支持host头域

##### 长连接

Http1.1 支持长连接和请求的流水线处理，在一个TCP连接上可以传送多个Http请求和响应，减少了建立和关闭连接的消耗和延迟，并且在Http1.1中默认开启

长连接和请求流水线



​	HTTP1.0最早在网页中使用是在1996年，那个时候只是使用一些较为简单的网页上和网络请求上，而HTTP1.1则在1999年才开始广泛应用于现在的各大浏览器网络请求中，同时HTTP1.1也是当前使用最为广泛的HTTP协议。 主要区别主要体现在：

- **缓存处理**，在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略；
- **带宽优化及网络连接的使用**，HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接；
- **错误通知的管理**，在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除；
- **Host头处理**，在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）；
- **长连接**，HTTP 1.1支持长连接（PersistentConnection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启Connection： keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。

同时也支持打开多个TCP连接，也支持流水线

### [http2.0](https://juejin.im/post/5a4dfb2ef265da43305ee2d0)

HTTP/1.x 实现简单是以牺牲性能为代价的：

- 客户端需要使用多个连接才能实现并发和缩短延迟；
- 不会压缩请求和响应首部，从而导致不必要的网络流量；
- 不支持有效的资源优先级，致使底层 TCP 连接的利用率低下。

​	HTTP2.0大幅度的提高了web性能，在HTTP1.1完全语意兼容的基础上，进一步减少了网络的延迟。实现低延迟高吞吐量。对于前端开发者而言，减少了优化工作。本文将重点围绕以下几点新特性的作用、工作过程以及如何更出色的完成了优化工作来介绍HTTP2.0。

- 二进制分帧

  HTTP/2.0 将报文分成 HEADERS 帧和 DATA 帧，它们都是二进制格式的。

  在通信过程中，只会有一个 TCP 连接存在，它承载了任意数量的双向数据流（Stream）。

  - 一个数据流（Stream）都有一个唯一标识符和可选的优先级信息，用于承载双向信息。
  - 消息（Message）是与逻辑请求或响应对应的完整的一系列帧。
  - 帧（Frame）是最小的通信单位，来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。

- 首部压缩

  HTTP/1.1 的首部带有大量信息，而且每次都要重复发送。

  HTTP/2.0 要求客户端和服务器同时维护和更新一个包含之前见过的首部字段表，从而避免了重复传输。

  不仅如此，HTTP/2.0 也使用 Huffman 编码对首部字段进行压缩。

- 流量控制

  

- 多路复用

- 请求优先级

- 服务器推送

  HTTP/2.0 在客户端请求一个资源时，会把相关的资源一起发送给客户端，客户端就不需要再次发起请求了。例如客户端请求 page.html 页面，服务端就把 script.js 和 style.css 等与之相关的资源一起发给客户端。

1. 二进制分帧

# 传输层

​	传输层为应用进程之间提供端到端的逻辑通信。目前主要由两个协议，分别是TCP协议和UDP协议。

​	两个对等运输实体在通信时传送的数据单元叫运输协议数据单元。TCP 传输的协议数据单元是TCP报文段，UDP传送的协议数据单元是UDP报文。

### 用户数据协议（UDP）

##### 简介

​	UDP 是User Datagram Protocol的简称， 中文名是**用户数据报协议**，是OSI（Open System Interconnection，开放式系统互联） 参考模型中**一种无连接的传输层协议**，提供面向事务的简单不可靠信息传送服务，但在某些情况下UDP是一种最有效的传输协议。

##### UDP报文组成

![](../assets/UDP%E6%8A%A5%E6%96%87%E7%BB%84%E6%88%90.png)

​	注意UDP 添加的首部中没有序号。

```
2字节的源ip地址，端口号 2字节的目的端口号，
2字节长度（包含首部在内的UDP报文段长度），2字节检验和
```

### 输控制协议(TCP)

##### 简介

​	TCP（Transmission Control Protocol，传输控制协议) 是一种面向连接的、可靠的、基于字节流的传输层的协议。TCP传输控制协议：可靠传输协议（ARQ），流量协议和拥塞控制

##### TCP报文组成

```
1.源端口号，目的端口号
2.序号 我产生的序列seq 是我发送的  确认号 期望值
3.首部长度（TCP首部长度是多少，但是由于TCP有选项字段，所以是可变的），ACK FIN 等首部码 状态码 接收窗口（主要用于流量控制）
4.互联网检验和，TCP是有检验和的 紧急数据指针（必须通知接收方的上层实体，我刚才也说了，TCP接受到包后，不是立即提交到）
```

##### TCP 首部详解

​	tcp 首部的格式如下：

![](../assets/TCP%E9%A6%96%E9%83%A8.png)

- 源端口、目标端口：4个字节

- 序号：**表示当前数据包是整个数据的第几个字节**。tcp是将数据分段发送，每一段都包含若干个字节，为了让接收方能正确拼接数据包，需要有序号信息。序号具体为当前数据包的首字节所在的原整个发送文件中的字节序号。如下图所示：

  ![](../assets/tcp%20%E9%A6%96%E9%83%A8%E5%BA%8F%E5%8F%B7.png)

- 确认号：由接收方发送，接收方在收到发送方发送的数据包后，将会给发送方返回一个确认消息，**其中的确认号就表示当前发送方接下来应该发送第几个字节**。如上图中，发送方首先将第一个数据包发送给接收方，接收方收到“1 2 3 4”所在的数据包后，计算得出接下来发送方应该从第五个字节开始发送数据包，此时便会给发送方返回一个确认信息，确认自己收到了“1 2 3 4”数据包，通知发送方应该从第五个字节开始的位置继续发送数据包。

>  确认号是当前收到的，是接收方用于表明已经接受了多少，序列号则根据对方的确认号，确定自己应该从第几个数字开始发送。

- 数据偏移：4位二进制，用来说明tcp数据包从哪里开始时tcp数据部分。因为tcp首部由20字节固定首部和长度可变的选项部分组成，所以需要记录整个tcp首部的长度，不然无法知道数据部分从哪里开始。

  具体的细节：4位二进制的范围是0-15，一个1表示4个字节，所以tcp首部的最长字节是4 x 15 = 60个字节，去掉固定长度20个字节，可变长度最长40个字节。

- 保留：6位2进制，没有用。

- 首部标记位：

  - URG：urgent，表示当前发送数据包比较紧急，不需在发送方的tcp缓存中排队，直接发送，如停止发送命令。
  - PSH：push，与URG相对应，表示当前发送的数据包较为紧急，不需要在接收方的tcp缓存中排队，让接收方优先读取该数据包。
  - ACK：acknowledgement，确认标志，若为0，则表示当前的确认号无效，为1，则表示当前确认号有效。
  - SYN：synchronous，同步标志位，建立请求时会用到，稍后三次握手详解。
  - RST：reset，如果该位取值为1，则表明当前tcp连接出现了严重问题，必须得重新建立连接才能取得正常通信。如点击网页的刷新按钮（异常中断）。
  - FIN：finish，最后数据包传递完，要释放连接，此时 FIN 的值就为1。

- 窗口：通知对方当前接收窗口的大小，让对方设置好发送窗口大小，防止出现连续发送数据包超过接收窗口大小的情况。

- 校验和：校验数据。

- 紧急指针：指明当前需要紧急处理的数据包首部的最后一个字节的位置。

- 选项：可变长度部分内容，有些tcp包有，有些没有，规定一些额外数据。如单个tcp数据包的最大长度（在抓包时可以看到 MISS = 1460，就是这个含义）

- 填充：保证tcp首部字节数是4的倍数。

##### 一个tcp传输实例

​	以下是一个windows xp向一个网站发送请求的真实抓包分析实例：

![](../assets/tcp传输实例.png)

##### 特点

- 面向连接的传输协议
- 全双工 通信两侧即使接收端也是发送端，
- 提供可靠交付服务
- 点对点传输的
- 基于字节流的，一个报文被分割成多个报文段，拼接后，传到上层套接字Socket

##### TCP协议如何来保证传输的可靠性

```
TCP提供一种面向链接的、可靠的字节流服务。其中，面向连接意味着两个使用TCP的应用在彼此交换数据的时候
必须先建立起一个tcp连接。在一个TCP连接中，仅有两方进行彼此通信；而字节流服务意味着两个应用程序，通过TCP连接交换8bit字节构成的字节流，TCP不在字节流中插入记录标符。

对于可靠性，TCP通过以下方式进行保证
1.数据包校验：校验码 反码相加为1
2.对失序数据包重排序 
3.丢弃重复数据，（丢弃重发，分组流水线重发）
4.应答机制 TCP收到发自TCP连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒
5.超时重发 TCP发出一个段后，它启动一个定时器，等待目的段确认收到这个报文段

6.流量控制，TCP连接的每一方都有固定大小的缓冲空间，TCP使用的流量控制协议是可变大小的滑动窗口协议
```



##### 可靠传输的实现

ARQ协议：停止等待ARQ和连续ARQ协议，ARQ其实就是自动重新请求，超时重发，只不过一个阻塞一个不阻塞

它使用确认和超时两个机制，来判断数据的丢失并进行重传

​	可靠传输的工作原理——停止等待协议，其工作原理如图：

![](../assets/%E5%81%9C%E6%AD%A2%E7%AD%89%E5%BE%85%E5%8D%8F%E8%AE%AE.png)

​	由图可以看到，无差错情况下发送方和请求方一应一答，如果第一个数据包丢失，发送方会在一个比往返时间（RTT, Round-Trip Time）略长的时间之后再发送数据包。

​	**确认丢失和确认迟到情况的处理：**（出现差错的时候，差错只有两种，丢失和延迟）

![](../assets/%E7%A1%AE%E8%AE%A4%E4%B8%A2%E5%A4%B1%E5%92%8C%E7%A1%AE%E8%AE%A4%E8%BF%9F%E5%88%B0.png)

​	以上的核心是：只要接收方没有告诉发送方已经收到数据包，发送方就认为接收方没有收到，再重新发送数据。**以上的可靠传输协议称为自动重传请求ARQ(Automatic Repeat reQuest)**。ARQ表明重传的请求是自动进行的。 一段时间没有收到ACK就会重传，接收方重复接收后会丢弃，A收到延迟的确认，但是会丢弃

​	停止等待协议的优点是简单，缺点是信道利用率太低。

![](../assets/%E4%BF%A1%E9%81%93%E5%88%A9%E7%94%A8%E7%8E%87.png)

​	信道利用率的计算公式如下：
$$
U = \frac{T_D}{T_D + RTT + T_A}
$$
​	其中，Td 是发送时间，RTT是往返时间，Ta 是确认接收时间。

​	由此引入**流水线传输技术**：

![](../assets/%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93%E6%B5%81%E6%B0%B4%E7%BA%BF%E4%BC%A0%E8%BE%93.png)

​	当前计算机网络中TCP使用的是流水线传输方式，使用协议为**连续ARQ（Automatic Repeat reQuest）协议**。

![](../assets/%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93%E8%BF%9E%E7%BB%ADARQ%E5%8D%8F%E8%AE%AE.png)

​	由图可见，发送方维持一个发送窗口，此处发送窗口的长度是5，发送方开始时先发送五个数据包，等到第一个数据包确认后，就将发送窗口向右滑动一位，再发下一个数据包（实际实现是将1号数据包从缓存中清除）。

​	但以上流水线传输方式依旧存在问题，就是接收方每接收到一个包就需要返回一个确认信息，效率不高，可采用累积确认改进，即收到连续的包数据时，每隔三个数据包返回一个确认信息，确认信息为收到的第三个数据包的序号，如果中间发生中断，导致接收到的数据包不连续，则就返回中断处前一个接收到的包的序号（如收到1、2、4包，则就返回2）。

##### 

### TCP的链接管理

传输连接有三个阶段：建立连接、数据传送、连接释放。

TCP的连接建立都采用**客户服务机方式**，主动发起连接建立的应用进程叫客户（Client），被动等待连接建立的应用进程叫服务器（Server）。

##### **连接--三次握手**



![](../assets/tcp%20%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.png)

过程详解：

1. 客户端先向服务器发送一个同步请求，其中SYN 同步标记位标记为1，ACK确认标志标记为0（因为没有确认号），序号为随便的一个数字x。

2. 服务器接受到客户端发起的同步请求，返回一个同步响应，其中SYN同步位标记位1，ACK确认标志标记位1，ack确认号就为x+1，序号为自己随机生成的一个数字y。

3. 客户端收到服务器的同步响应，发送一个确认响应，其中ACK确认标志位为1，ack确认号为y+1，seq序号为x+1。其实例如下图所示：

   ![](../assets/tcp 三次握手实例.png)



##### 释放--四次挥手

- 原理图如下：

  ![](../assets/tcp4%E6%AC%A1%E6%8C%A5%E6%89%8B.png)

- 过程详解：

  ​	数据传输结束后，通信的双方都可以释放连接，现在假设客户A的应用进程先发出tcp释放报文段，并停止发送数据，主动关闭tcp连接。

  1. A 将设置tcp首部FIN标志位为1，seq序号为u，等待B确认；**客户端停止发送数据**
  2. B发出确认，确认号ack = u + 1，seq = v；此时，TCP服务器进程通知高层应用进程，从A到B这个方向的连接就释放了，TCP 连接处于半关闭状态。B若发送数据，A仍要接收。**注意这一步仍然在发送数据**。
  3. 若B已经没有要向A发送的数据，其应用进程就通知TCP服务器进程释放连接。此时设置 TCP 报文首部的FIN=1，ACK = 1，seq = w， ack = u + 1；**close-wait过后 服务器端停止发送数据**  进入Last-ACK状态，就缺客户端再来一个ACK
  4. A给B返回一个响应，TCP报文首段设置ACK = 1， ack = w + 1，seq = u + 1。

  经过以上四个步骤，客户端会再等两个MSL(Maximum Segment Lifetime, 报文最长存活时间)时间，之后双方彻底断开连接。

  连接建立状态 	连接建立状态

  客户端发出FIN 进入Fin-Wait状态 	收到并返回ACK 进入 close-wait状态

  客户端接受到接受到ACK变成Fin-Wait2状态，等待 

  服务端发出FIN 自身进入 Last-ACK状态  客户端收到FIN后，发出ACK后自身进入Time-Wait状态，等待2个MML后关闭，MML为数据包最大存留长度，等待两个 是怕有包延迟了

  但是Time-Wait太长也会出现问题



##### 补充：ACK和Seq

Seq就是序列号，是发送端生成的，接收端收到后发送 ACK 应该等于Seq+1 告诉我前Seq个已经收到，现在请求Seq+1的数据





### TCP和UDP的区别 ✅

TCP和UDP都是传输层（运输层）的协议

1. TCP是面向连接的，UDP是无连接的
2. TCP是可靠的，UDP是不可靠的
   也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达；UDP尽最大努力交付，即不保证可靠交付
3. TCP的可靠主要靠ARQ协议，主要分停止等待ARQ和连续ARQ两者，然后 ARQ协议包含了收到确认（序号标识和确认应答），超时重传，重复丢弃
   流水线重传，然后还有控制流量的滑动窗口协议
4. TCP只支持点对点通信（其实本质还是TCP是面向连接的有关），
   UDP支持一对一，一对多，多对一，多对多的通信模式
5. TCP是面向字节流的，UDP是面向报文的//TCP面向字节流 
   收发双方都会有一个本地tcp缓存，使用tcp协议收发数据时，发送方会将本地待发送文件中的若干个字节复制到本地tcp缓存中，在缓存中进行添加首部等处理，然后发送到接收方的的tcp缓存中，接收方再去除首部，拼装数据到本地存储。
6. TCP拥有拥塞控制机制；UDP没有拥塞控制机制，适合媒体通信
7. TCP首部开销（20个字节）比UDP的首部开销（8个字节）要大

### TCP拥塞处理 ✅

​	前面内容为tcp的传输流量控制（即通过停止等待协议和滑窗技术保证让发送方的发送速率不要太快，让接收方来得及接受），接下来为tcp的拥塞控制。

- 什么是拥塞

  大量的数据发送超过了带宽能承受的范围导致网络变慢。拥塞是一个全局性过程，涉及到所有的主机、所有的路由器，以及降低网络传输性能的所有有关因素。

- 出现拥塞的条件

  对资源需求的总和 > 可用资源。如宽带一共50M，同一时间内出现大量的数据包收发，导致1s内发送的数据量大于50M，此时就出现拥塞。

- 拥塞控制与流量控制的区别

  但是这里已经说了流量控制和拥塞控制，虽然它们都是窗口类型的控制协议，但是一个是针对全局性的一个过程，一个是点对点的流量传输过程，

  慢开始

  拥塞避免

  快重传

  快恢复 

  大体这么几个阶段

  - 资源拥塞是一个全局性过程，涉及到所有的主机、所有的路由器，以及降低网络传输性能的所有有关因素。

  - 流量控制往往指在给定的发送端和接收端之间点对点的流量控制，所要做的就是抑制发送端的流量发送速率，以便使接收端来得及接收。

    否则会因为接收端接收不到 产生大量的丢包 导致发送方大量超时重发，进而陷入恶性循环消耗系统资源

- 拥塞控制的作用

  ![](../assets/%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%9A%84%E4%BD%9C%E7%94%A8.png)

- 实现原理：拥塞窗口（慢开始算法、拥塞避免、快重传、快恢复）

  ​	发送方维持拥塞窗口cwnd(congestion window)，拥塞窗口的原则是：只要网络没有出现拥塞，发送窗口就再大一些，以便同时发送更多的包；只要网络出现拥塞，就缩小发送窗口，减少同时发出的包。

  真的有点像滑动窗口协议的变形

  ​	如下所示：

  - **慢开始与拥塞避免**：发送方和接受方两者之间才开始发送数据时，发送方先发一个包，如果接收方的返回结果显示一个包没丢，发送方就增大拥塞窗口，一次发送两个，若接收方返回结果显示一个包没丢，发送方就再增大拥塞窗口，一次发送四个，以此类推...

    缓慢增大拥塞窗口，应该可以自行设置增量的大小

    ![](../assets/%E6%85%A2%E5%BC%80%E5%A7%8B%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86.png)

    慢开始算法有一个**慢开始门限**，门限之前拥塞窗口是指数级增加，到慢开始门限后就一个一个增加，如下图所示：

    ![](../assets/%E6%85%A2%E5%BC%80%E5%A7%8B%E9%97%A8%E9%99%90.png)

    本图中慢开始门限是16，到达16后拥塞窗口每次加一。注意在拥塞窗口到达24时时，出现网络拥塞，此时重新开始慢开始算法，并且将慢开始门限调整为12。

    遇到拥塞后，重新开始慢开始算法

    慢开始算法，一开始是指数级别的增长，之后到达一定的thresh holder之后就开始缓慢增长

  - **拥塞避免**

    上图已经展示了拥塞避免过程，即在拥塞避免阶段，将拥塞窗口控制为按线性规律增长，使得网络比较不容易出现拥塞。拥塞避免阶段，让拥塞窗口，开始一个一个增加，线性规律增长

    达到阀值 降低达到慢开始的门限

  - **慢开始与快重传、快恢复**

    接收方丢包时，立马回复丢包信息（连续发三个丢包信息，发送方通过接收到的数量来判断网有没有堵），让发送方重新发送，而不是按照约定的每隔五个包发送一次确认信息，等待一组包发完后再给确认哪个数据包丢了。

    ![](../assets/%E5%BF%AB%E9%87%8D%E4%BC%A0.png)

  - **快恢复**

    快恢复相对于慢开始效率要高很多，快恢复就是让拥塞窗口直接达到新的慢开始门限

    就是从拥塞避免阶段跌落，开始重新走一遍拥塞避免算法，线性增长
  
  

滑动窗口协议通过第四部分，发送窗口之外的缓冲区内暂时不允许发送的数据，来进行流量控制，或者说，控制窗口的长度

### TCP流量协议 

连续ARQ，即流水线发送，通常和滑动窗口协议一起使用的，维持一个滑动窗口，收到确认之后，发送窗口往前，而窗口内的都是一起发的



![](/Users/Haoyu/Documents/Notes-For-Interviews/技术资料/assets/%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93%E8%BF%9E%E7%BB%ADARQ%E5%8D%8F%E8%AE%AE.png)

​	由图可见，发送方维持一个发送窗口，此处发送窗口的长度是5，发送方开始时先发送五个数据包，等到第一个数据包确认后，就将发送窗口向右滑动一位，再发下一个数据包（实际实现是将1号数据包从缓存中清除）。

​	但以上流水线传输方式依旧存在问题，就是接收方每接收到一个包就需要返回一个确认信息，效率不高，可采用累积确认改进，即收到连续的包数据时，每隔三个数据包返回一个确认信息，确认信息为收到的第三个数据包的序号，如果中间发生中断，导致接收到的数据包不连续，则就返回中断处前一个接收到的包的序号（如收到1、2、4包，则就返回2）。

##### 滑动窗口发送窗口

如下图所示，发送窗口中有四个概念：：已发送并收到确认的数据（不在发送窗口和发送缓冲区之内）、已发送但未收到确认的数据（位于发送窗口之内）、允许发送但尚未发送的数据（位于发送窗口之内）、发送窗口之外的缓冲区内暂时不允许发送的数据。

##### 滑动窗口接收窗口

接收窗口中也有四个概念：已发送确认并交付主机的数据（不在接收窗口和接收缓冲区之内）、未按序收到的数据（位于接收窗口之内）、允许的数据（位于接收窗口之内）、不允许接收的数据（位于发送窗口![wKgBEFq2ZVKAPD0_AAhhsCYdx4o60](/Users/Haoyu/Desktop/wKgBEFq2ZVKAPD0_AAhhsCYdx4o60.jpeg)之内）



![滑动窗口](../assets/滑动窗口.png)

##### 窗口特点

（1）凡是已经发送过的数据，在未收到确认之前，都必须暂时保留，以便在超时重传时使用。

（2）只有当发送方A收到了接收方的确认报文段时，发送方窗口才可以向前滑动几个序号。

（3）当发送方A发送的数据经过一段时间没有收到确认（由超时计时器控制），就要使用回退N步协议，回到最后接收到确认号的地方，重新发送这部分数据。

##### 滑动窗口的大小：



### TCP长连接 短连接

- 长连接

  所谓长连接，指在一个TCP连接上可以连续发送多个数据包，**在TCP连接保持期间，如果没有数据包发送，需要双方发检测包以维持此连接**，一般需要自己做在线维持（不发生RST包和四次挥手）。

  发送检测包 即心跳包，来维持长连接，我说心跳的概念是哪里来的 

  连接→数据传输→保持连接(心跳)→数据传输→保持连接(心跳)→……→关闭连接（一个TCP连接通道多个读写通信）； 

- 短连接

  短连接是指通信双方有数据交互时，就建立一个TCP连接，数据发送完成后，则断开此TCP连接（管理起来比较简单，存在的连接都是有用的连接，不需要额外的控制手段）；

  连接→数据传输→关闭连接；

- 应用场景

  ​	**长连接多用于操作频繁（读写），点对点的通讯**，而且连接数不能太多情况。每个TCP连接都需要三步握手，这需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多，所以每个操作完后都不断开，次处理时直接发送数据包就OK了，不用建立TCP连接。例如：**数据库的连接用长连接**， 如果用短连接频繁的通信会造成socket错误，而且频繁的socket 创建也是对资源的浪费。

   	**而像WEB网站的http服务一般都用短链接**（http1.0只支持短连接，1.1keep alive 带时间，操作次数限制的长连接），因为长连接对于服务端来说会耗费一定的资源，而像WEB网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源，如果用长连接，而且同时有成千上万的用户，如果每个用户都占用一个连接的话，那可想而知吧。**所以并发量大，但每个用户无需频繁操作情况下需用短连好**；

  ​     在长连接中一般是没有条件能够判断读写什么时候结束，所以必须要加长度报文头。读函数先是读取报文头的长度，再根据这个长度去读相应长度的报文。

### TCP Time-Wait状态 ✅

- 友好： Time-Wait状态是友好的，因为迟发的报文包最多存活maxinum segment lifetime，而Time-wait状态时长两个MSL，所以可以避免收到服务器SYN码后 因网络延迟 迟收到的数据。如果没有Time-Wait状态，可能旧连接的数据会被新连接收到，保证迟来的数据包可以被识别并抛弃。
- 劣势 Time-Wait状态，一个TCP连接不结束依旧会会但是太长的Time-Wait在面对高并发的短连接场景的时候，会有太多的端口占用，导致资源的浪费和连接的失败

##### 问题出现

1. 端口是有限的。高并发可以让服务器在短时间范围内同时占用大量端口，而端口有个0~65535的范围，并不是很多，刨除系统和其他服务要用的，剩下的就更少了。
2. 在这个场景中，短连接表示“业务处理+传输数据的时间 远远小于 TIMEWAIT超时的时间”的连接。这里有个相对长短的概念，比如，取一个web页面，1秒钟的http短连接处理完业务，在关闭连接之后，这个业务用过的端口会停留在TIMEWAIT状态几分钟，而这几分钟，其他HTTP请求来临的时候是无法占用此端口的。单用这个业务计算服务器的利用率会发现，服务器干正经事的时间和端口（资源）被挂着无法被使用的时间的比例是 1：几百，服务器资源严重浪费。（说个题外话，从这个意义出发来考虑服务器性能调优的话，长连接业务的服务就不需要考虑TIMEWAIT状态。同时，假如你对服务器业务场景非常熟悉，你会发现，在实际业务场景中，一般长连接对应的业务的并发量并不会很高）
  综合这两个方面，持续的到达一定量的高并发短连接，会使服务器因端口资源不足而拒绝为一部分客户服务。同时，这些端口都是服务器临时分配，无法用SO_REUSEADDR选项解决这个问题:(

##### 如何解决

1.不符合解决原则的办法：

​	linux没有在sysctl或者proc文件系统暴露修改这个TIMEWAIT超时时间的接口，可以修改内核协议栈代码中关于这个TIMEWAIT的超时时间参数，重编内核，让它缩短超时时间，加快回收；







### 补充：设计可靠UDP协议



# 网络层

偏硬件了，我赌应该面试到的不多

### IP地址的分类

```

```



### 以及IP地址以及ARP协议

```
ARP协议实现了IP地址和物理地址的映射关系

首先，每台主机都会在自己的ARP缓冲区中建立一个ARP列表，以表示IP地址和MAC地址的对应关系。
当源主机需要将一个数据包要发送到目的主机时，会首先检查自己ARP列表中是否存在该IP地址对应的MAC地址：
如果有，就直接将数据包发送到这个MAC地址；
如果没有，就向本地网段发起一个ARP请求的广播包，查询此目的主机对应的MAC地址。

```



# 面试题

### 网关的作用是什么

​	就是将两个使用不同协议的网络段连接在一起的设备。它的作用就是对两个网络段中的使用不同传输协议的数据进行互相的翻译转换。

​	连接不同网段，进行数据传输。